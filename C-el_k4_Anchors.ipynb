{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69eba05",
   "metadata": {},
   "source": [
    "# Anchors:\n",
    "In the following code, we will use data from https://www.nature.com/articles/s41586-021-03778-8\n",
    "\n",
    "In this case, we will align the last four connectome networks, corresponding to the latest stages of development: L2,L3, A1, A2\n",
    "\n",
    "In this notebook we are not working with weighted networks, only with the presence or not of a connection (Binary adjacency matrices).\n",
    "\n",
    "Also we have taken randomly 15% of the nodes as random\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefb8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numba import jit, njit\n",
    "from numba.types import bool_, int_, float32\n",
    "from math import comb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5785a",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c848c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichero leído: 0 tamaño (227, 183)\n",
      "Fichero leído: 1 tamaño (227, 183)\n",
      "Fichero leído: 2 tamaño (227, 183)\n",
      "Fichero leído: 3 tamaño (227, 183)\n",
      "Fichero leído: 4 tamaño (227, 183)\n",
      "Fichero leído: 5 tamaño (227, 183)\n",
      "Fichero leído: 6 tamaño (227, 183)\n",
      "Fichero leído: 7 tamaño (227, 183)\n"
     ]
    }
   ],
   "source": [
    "### Open the files\n",
    "tablas = 8\n",
    "n_grupo = 4\n",
    "\n",
    "d = {}\n",
    "D = \"Dataset\"\n",
    "for i in range(0,tablas):\n",
    "    d[\"group\" + str(i)] = pd.read_excel(\"datasets.ods\", sheet_name=D+str(i+1))\n",
    "    print('Read:',i, 'size', d[\"group\" + str(i)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d8624d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hipermatrix M with the data (Only the synapses) \n",
    "rows = d[\"group\" + str(i)].shape[0] - 3\n",
    "columns = d[\"group\" + str(i)].shape[1] - 3\n",
    "\n",
    "M = np.zeros((tablas,rows,columns))\n",
    "for i in range(0, tablas):\n",
    "    Data = d['group' + str(i)]\n",
    "    M[i,:,:] = Data.iloc[3:,3:]\n",
    "    \n",
    "## Since we work with same number of nodes, we want them equal and square (zeros when no connections)\n",
    "M_square = np.zeros((tablas, rows, rows))\n",
    "M_square[:,:, 0:columns] = M[:,:,:]\n",
    "\n",
    "## Binarization: No weights\n",
    "#Lo queremos BINARIO, ignorando su peso (Luego pensar cómo se haría con el peso)\n",
    "M_square_bin = np.zeros((tablas,rows,rows))\n",
    "for i in range(tablas):\n",
    "    for j in range(rows):\n",
    "        for k in range(columns):\n",
    "            if (M[i,j,k] >= 1):\n",
    "                M_square_bin[i,j,k] = 1\n",
    "                \n",
    "Nx = rows # Number of nodes (we imposed rows == columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6812211",
   "metadata": {},
   "source": [
    "### GROUP INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b02f065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grupos: Sensory, Inter, Motor, Modulatory, Muscle, Other\n",
      "SIZE GROUPS: [65 44 42 29 32 12]\n",
      "***********************************\n",
      "First node in each group [  0  65 109 151 180 212]\n",
      "Last node in each group [ 65 109 151 180 212 224]\n"
     ]
    }
   ],
   "source": [
    "# Groups from the database\n",
    "Sensory = 69-5 #0\n",
    "Inter = 113-70 # 1\n",
    "Motor = 155-114 #2\n",
    "Modulatory = 184-156 #3\n",
    "Muscle = 216-185 #4 \n",
    "Others = 228-217 #5\n",
    "\n",
    "size_groups = np.array([Sensory, Inter, Motor, Modulatory, Muscle, Others]) + 1 #Started in 0\n",
    "n_groups = len(size_groups)\n",
    "start_groups = np.zeros(n_groups)\n",
    "end_groups = np.zeros(n_groups)\n",
    "\n",
    "\n",
    "print('grupos: Sensory, Inter, Motor, Modulatory, Muscle, Other')\n",
    "print('SIZE GROUPS:', size_groups)\n",
    "\n",
    "\n",
    "#Para evitar trabajar con diccionarios (por NUMBA), vamos a hacer matrices \n",
    "# Cada matriz tiene el tamaño de la de mayor, pero luego las vamos cortando\n",
    "rows_g, columns_g = size_groups.max(), size_groups.max()\n",
    "\n",
    "size_suma = 0\n",
    "start_groups[0] = 0\n",
    "for i in range(n_groups):\n",
    "    size = size_groups[i]\n",
    "    if (i != n_groups-1):\n",
    "        start_groups[i+1] = int(size_suma + size)\n",
    "    size_suma = size_suma + (size) \n",
    "#end\n",
    "for i in range(0,n_groups):\n",
    "    if (i!= n_groups-1):\n",
    "        end_groups[i] = start_groups[i+1]\n",
    "    else:\n",
    "        end_groups[i] = Nx\n",
    "start_groups = start_groups.astype(int)\n",
    "end_groups = end_groups.astype(int)\n",
    "\n",
    "print('***********************************')\n",
    "print('First node in each group', start_groups)\n",
    "print('Last node in each group', end_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955c46f",
   "metadata": {},
   "source": [
    "## ENERGY FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015dfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta):\n",
    "\n",
    "    A_1 = overlap_1 + alpha\n",
    "    B_1 = (Edges_L - overlap_1 + beta)\n",
    "    C_1 = Edges_L + alpha + beta\n",
    "    \n",
    "    A_0 = overlap_0 + alpha\n",
    "    B_0 = (Edges_NoL - overlap_0 + beta)\n",
    "    C_0 = Edges_NoL + alpha + beta\n",
    "    \n",
    "    #  [ math.lgamma(n+1) == log(n!) ]\n",
    "    H1 = math.lgamma(A_1)+ math.lgamma(B_1) - math.lgamma(C_1) \n",
    "    H0 = math.lgamma(A_0)+ math.lgamma(B_0) - math.lgamma(C_0) \n",
    "    \n",
    "    H = -(H1 + H0)\n",
    "    return H\n",
    "    \n",
    "    \n",
    "@jit(nopython=True)\n",
    "def overlap_total_prob(L_f, A_f, P_inv_f):\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0 = np.zeros((K))\n",
    "    ovlp_1 = np.zeros((K))\n",
    "    for k in range(0,K):\n",
    "        for f in range(0,Ny): \n",
    "            for c in range(0,Nx):\n",
    "                p_f=int(P_inv_f[k,f])\n",
    "                p_c=int(P_inv_f[k,c])  \n",
    "                \n",
    "                valor_L, valor_A = L_f[f,c], A_f[k,p_f,p_c]\n",
    "                \n",
    "                ovlp_0[k] = ovlp_0[k] + (1-valor_L)*(1-valor_A )\n",
    "                ovlp_1[k] = ovlp_1[k] + valor_L*valor_A\n",
    "                \n",
    "                \n",
    "    ovlp_1 = int(sum(ovlp_1))\n",
    "    ovlp_0 = int(sum(ovlp_0))\n",
    "    return ovlp_0, ovlp_1\n",
    "\n",
    "\n",
    "@jit(nopython=True) # The blueprint is the average of the observations (taking into account the mapping)  \n",
    "def L_wiring(A_f, P_inv_f):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "    L_new_f = np.zeros((Nx,Ny))\n",
    "    \n",
    "    for i in range(0,Nx):\n",
    "        for j in range(0,Ny):\n",
    "            for k in range(0,K):\n",
    "        \n",
    "                p1 = int(P_inv_f[k,i]) # Mapping of the observations\n",
    "                p2 = int(P_inv_f[k,j]) # Mapping of the observations\n",
    "                L_new_f[i,j] += A_f[k,p1,p2]\n",
    "            valor_lnew=1/K* L_new_f[i,j]\n",
    "            L_new_f[i,j] = round( valor_lnew ) \n",
    "            # If valor_lnew = 0, L=0 (we could establish L=1, but it is more probable to not have a connection)\n",
    "    \n",
    "    return L_new_f\n",
    "\n",
    "\n",
    "#### Some algorithm for sorting\n",
    "@jit(nopython=True)\n",
    "def partition(array,  etiquetas, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if array[i] < array[begin]:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "            etiquetas[i], etiquetas[pivot] = etiquetas[pivot], etiquetas[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    etiquetas[pivot], etiquetas[begin] = etiquetas[begin], etiquetas[pivot] \n",
    "\n",
    "    return pivot\n",
    "@jit(nopython=True)\n",
    "def quicksort(array, etiquetas, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    if begin >= end: #To end\n",
    "        return\n",
    "    pivot = partition(array,  etiquetas, begin, end)\n",
    "    \n",
    "    #Order right and left\n",
    "    quicksort(array, etiquetas, begin, pivot-1)\n",
    "    quicksort(array,  etiquetas, pivot+1, end)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2881b5b",
   "metadata": {},
   "source": [
    "## INITIAL CONDITIONS\n",
    "\n",
    "We will align the 4 last networks: L2, L3, A1, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ce360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATIONS\n",
      "(4, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "Nx = rows # Nodes\n",
    "K = 4 # Number of networks\n",
    "alpha,beta = 5,2 # Values for the beta prior distribution \n",
    "Edges = Nx*Nx \n",
    "micropasos = Edges*K #Microsteps for each MCMC\n",
    "A = np.zeros((K,Nx,Nx))\n",
    "A = M_square_bin[4:, :,:] #Only the latest four                \n",
    "print('OBSERVATIONS')  \n",
    "print(A.shape)\n",
    "####################################\n",
    "\n",
    "## INITIALIZATION ##\n",
    "\n",
    "L_ini = np.zeros((Nx,Nx))\n",
    "P_ini_0 = np.zeros((K,Nx))\n",
    "P_inv_ini_0 = np.zeros((K,Nx))\n",
    "\n",
    "# We inizialize with the Blueprint = L2\n",
    "L_ini = (A[0,:,:]).copy()\n",
    "\n",
    "groups_ini = np.zeros((K,Nx)) #Groups label\n",
    "for m1 in range(K):\n",
    "    for i_g in range(n_groups):\n",
    "        start = start_groups[i_g]\n",
    "        end = end_groups[i_g]\n",
    "        groups_ini[m1, start:end] = i_g\n",
    "        \n",
    "## Overlaps\n",
    "ovlp_ini0, ovlp_ini1 = overlap_total_prob(L_ini,A,P_inv_ini_0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee46b99",
   "metadata": {},
   "source": [
    "## Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b4ac0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Random anchors:\n",
      "[ 11.  59.  42.  27.  61.  31.  57.  26.  30.  66.  68.  72.  69.  90.\n",
      "  65. 131. 109. 130. 110. 120. 142. 175. 159. 157. 163. 191. 210. 203.\n",
      " 185. 222.]\n",
      "Anchors in each group [9. 6. 6. 4. 4. 1.]\n",
      "News [ 30  86 124 160 185 213] [ 86 124 160 185 213 224]\n"
     ]
    }
   ],
   "source": [
    "grupos_extra = np.zeros((n_groups))\n",
    "\n",
    "# 15% Anchors in each group\n",
    "anchors_gr = size_groups*0.15\n",
    "anchors_gr = anchors_gr.astype(int)\n",
    "grupos_extra = grupos_extra + anchors_gr\n",
    "Anchors_prop = np.zeros((sum(anchors_gr)))\n",
    "count = 0\n",
    "for i_g in range(len(anchors_gr)):\n",
    "    numbers = anchors_gr[i_g]\n",
    "    start, end = start_groups[i_g], end_groups[i_g]\n",
    "    posis = np.random.randint(start,end, size = numbers)\n",
    "    size_1 = len(posis)\n",
    "    posis = np.unique(posis) #unique also ordered\n",
    "    size_2 = len(posis)\n",
    "\n",
    "    while (size_2 < numbers):\n",
    "        posi_extra = np.zeros(numbers - size_2)\n",
    "        for i_p in range(numbers - size_2):\n",
    "            posi_extra[i_p] = np.random.randint(start,end)\n",
    "       \n",
    "        posis = np.concatenate((posis, posi_extra))  \n",
    "        posis = np.unique(posis)  \n",
    "        size_2 = len(posis)        \n",
    "        \n",
    "    Anchors_prop[count:count +numbers] = posis\n",
    "    count = count+numbers\n",
    "\n",
    "\n",
    "\n",
    "print()\n",
    "print('Random anchors:')\n",
    "print(Anchors_prop)\n",
    "\n",
    "Anchors = Anchors_prop\n",
    "start = len(Anchors) # To start the new initial position in groups\n",
    "print('Anchors in each group', grupos_extra)\n",
    "\n",
    "## Computing again the group positions\n",
    "start_anchor, end_anchor = np.zeros((n_groups)),np.zeros((n_groups))\n",
    "\n",
    "ini = start\n",
    "acum = 0\n",
    "for i_g in range(n_groups):\n",
    "    start_anchor[i_g] = start_groups[i_g] + ini-acum\n",
    "    acum = acum + grupos_extra[i_g]\n",
    "    end_anchor[i_g] = end_groups[i_g] + ini-acum\n",
    "\n",
    "start_anchor, end_anchor = start_anchor.astype(int), end_anchor.astype(int)\n",
    "print('News',start_anchor, end_anchor)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9fd6bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the anchors to repeat the experiment and have statistical\n",
    "d_store_anchors = {}\n",
    "string_anchors = \"anchors_store.pickle\"\n",
    "d_store_anchors[\"start_anchors\"] = start_anchor    \n",
    "d_store_anchors[\"end_anchor\"] = end_anchor\n",
    "d_store_anchors[\"anchors_group\"] = grupos_extra\n",
    "d_store_anchors[\"anchors_all\"] = Anchors\n",
    "file1 = open(string_anchors,\"wb\")\n",
    "pickle.dump( d_store_anchors, file1)\n",
    "file1 = open(string_anchors,\"wb\")\n",
    "pickle.dump( d_store_anchors, file1)\n",
    "prueba = pickle.load(open(string_anchors, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2384b56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def permu_groups_capa1_anchors_knwn(L_f, A_f, start_f,grupos_t, Anchors,grupos_extra): \n",
    "   \n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    N_groups = len(start_f)\n",
    "    start_2 = np.zeros((len(start_f)))\n",
    "    start_2[1:] = np.cumsum(grupos_extra)[:-1]\n",
    "    start_anchor = start_f - start_2   \n",
    "    start_anchor = start_anchor.astype(int)\n",
    "    \n",
    "    #Mappings\n",
    "    P_f = np.zeros((K,Nx)) #Mapping from L to A\n",
    "    P_inv_f = np.zeros((K,Nx)) #Mapping from A to L\n",
    "    P_new = np.zeros((K,Nx))\n",
    "    \n",
    "    \n",
    "    ### First setting the anchors\n",
    "    n_an = len(Anchors)\n",
    "    P_inv_f[:,:n_an] = Anchors\n",
    "    \n",
    "    # Second we order the blueprint and after the observations\n",
    "    # Blueprint:    \n",
    "    orden_L_in = np.zeros((Nx-n_an))\n",
    "    array_L = np.zeros((Nx-n_an ))\n",
    "    c_o = 0\n",
    "    for i in range(Nx):\n",
    "        if (i not in Anchors):\n",
    "            b = np.nonzero(L_f[i,:])\n",
    "            array_L[c_o] = i\n",
    "            orden_L_in[c_o] = b[0].size\n",
    "            c_o += 1\n",
    "     \n",
    "    orden_L = orden_L_in.copy()\n",
    "    quicksort(orden_L, array_L)\n",
    "    array_L = array_L[::-1]\n",
    "\n",
    "    grupos_L = np.zeros((Nx-n_an))\n",
    "    for  i_g in range(N_groups):\n",
    "        start = start_anchor[i_g]\n",
    "        if (i_g != N_groups-1):\n",
    "            end = start_anchor[i_g+1]\n",
    "        else:\n",
    "            end = Nx-n_an\n",
    "        grupos_L[start:end] = i_g\n",
    "    grupos_L = grupos_L.astype(int)\n",
    "    orden_L = orden_L_in.copy()\n",
    "    quicksort(orden_L, grupos_L )\n",
    "    grupos_L = grupos_L[::-1]\n",
    "\n",
    "    #Observations\n",
    "    for i in range(0,K):\n",
    "        orden_A_in = np.zeros((Nx- n_an))\n",
    "        array_A = np.zeros((Nx-n_an))\n",
    "        grupos_A = np.zeros((Nx-n_an))\n",
    "        c_o = 0\n",
    "        for i_orden in range(Nx):\n",
    "            if (i_orden not in Anchors):\n",
    "                b = np.nonzero(A_f[i,i_orden,:])\n",
    "                array_A[c_o] = i_orden\n",
    "                grupos_A[c_o] = grupos_t[i, i_orden]\n",
    "                orden_A_in[c_o] = b[0].size\n",
    "                c_o += 1\n",
    "        \n",
    "        orden_A = orden_A_in.copy()\n",
    "        quicksort(orden_A, array_A)  \n",
    "        array_A = array_A[::-1]\n",
    "\n",
    "        orden_A = orden_A_in.copy()\n",
    "        quicksort(orden_A, grupos_A)\n",
    "        grupos_A = grupos_A[::-1]\n",
    "\n",
    "        \n",
    "        array_A_L = np.zeros((Nx - n_an))\n",
    "        for i_n in range(Nx-n_an):\n",
    "            if ((grupos_A[i_n] == grupos_L[i_n])):\n",
    "                array_A_L[i_n] = array_A[i_n]\n",
    "            else:\n",
    "                count = 0\n",
    "                for i_nn in range(0, Nx-n_an):\n",
    "                    if ((grupos_A[i_nn] == grupos_L[i_n])): \n",
    "                        array_A_L[i_n] = array_A[i_nn]\n",
    "                        array_A[i_nn] = array_A[i_n]\n",
    "                        aux = grupos_A[i_nn]\n",
    "                        grupos_A[i_nn] = grupos_A[i_n]\n",
    "                        grupos_A[i_n] = aux\n",
    "                        count = 1\n",
    "                        break\n",
    "        array_A_L = array_A_L[np.argsort(array_L)]\n",
    "        P_inv_f[i,n_an:] = array_A_L\n",
    "        \n",
    "        for i_inv in range(0,Nx):\n",
    "            for j_inv in range(0,Ny):\n",
    "                if (P_inv_f[i,i_inv] == j_inv):\n",
    "                    P_f[i, j_inv]=i_inv\n",
    "    \n",
    "    P_todo = np.zeros((2,K,Nx))\n",
    "    P_todo[0,:,:] = P_f.copy()\n",
    "    P_todo[1,:,:] = P_inv_f.copy()\n",
    "\n",
    "    return P_todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bbea403b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "[[ 11  59  42  27  61  31  57  26  30  66  68  72  69  90  65 131 109 130\n",
      "  110 120 142 175 159 157 163 191 210 203 185 222   0   1   2   3   4   5\n",
      "    6   7   8   9  10  12  13  14  15  16  17  18  19  20  21  22  23  24\n",
      "   25  28  29  32  33  34  35  36  37  38  39  40  41  43  44  45  46  47\n",
      "   48  49  50  51  52  53  54  55  56  58  60  62  63  64  67  70  71  73\n",
      "   74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  91  92\n",
      "   93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 111 112\n",
      "  113 114 115 116 117 118 119 121 122 123 124 125 126 127 128 129 132 133\n",
      "  134 135 136 137 138 139 140 141 143 144 145 146 147 148 149 150 151 152\n",
      "  153 154 155 156 158 160 161 162 164 165 166 167 168 169 170 171 172 173\n",
      "  174 176 177 178 179 180 181 182 183 184 186 187 188 189 190 192 193 194\n",
      "  195 196 197 198 199 200 201 202 204 205 206 207 208 209 211 212 213 214\n",
      "  215 216 217 218 219 220 221 223]\n",
      " [ 11  59  42  27  61  31  57  26  30  66  68  72  69  90  65 131 109 130\n",
      "  110 120 142 175 159 157 163 191 210 203 185 222  56  54   1  41  44  15\n",
      "   60  10   8   3  16  32  25   6   0  55  58  63  17  19  53   4  34  29\n",
      "   38  36  46  39  52  24  49  64   9  50  43  45  28  40   5  13  62  12\n",
      "   47  18  37  33  48   2  21  23   7  20  51  35  14  22  89  95  71 106\n",
      "  103  98  75  96  97  80  83  73 107  79  84 102  67  94  88  85  99  92\n",
      "  100  93  78  77  81 104  91  87  82  76  74  70 105 108 101  86 147 137\n",
      "  114 132 140 115 121 143 122 119 117 113 129 118 145 150 136 124 134 141\n",
      "  127 116 133 148 128 112 125 149 144 146 126 123 138 135 139 111 162 156\n",
      "  164 176 171 167 160 179 161 173 165 177 166 172 155 168 169 170 153 154\n",
      "  174 158 178 151 152 195 183 184 187 192 190 194 199 181 202 193 186 182\n",
      "  180 211 198 206 200 188 189 196 209 204 201 207 197 205 208 219 212 221\n",
      "  214 217 216 213 215 223 218 220]\n",
      " [ 11  59  42  27  61  31  57  26  30  66  68  72  69  90  65 131 109 130\n",
      "  110 120 142 175 159 157 163 191 210 203 185 222  22  54  48  17  46  55\n",
      "    5  45  37  41  44  12  14  18  51  53   9  62  49   8  28  25  33   2\n",
      "   35  56   1  52  32  10  36   6  58   3   4  23  64  39  63  19  29  21\n",
      "   16  38  20  34  24  15  60  13  50   0  40   7  47  43  97  96  71  81\n",
      "   74  77 102  78 105  95  83 108 107  70  80  76 106  99  94  89  93  92\n",
      "  101  88  79  84  67  85  87  91  98  75 100 104  82 103  73  86 111 134\n",
      "  138 136 132 137 118 122 119 146 143 140 129 128 145 148 147 121 135 113\n",
      "  150 127 149 112 124 139 144 116 125 117 123 126 133 141 114 115 158 154\n",
      "  151 156 153 161 178 166 160 176 168 177 165 172 155 164 173 170 152 162\n",
      "  174 167 179 171 169 187 188 190 192 186 198 195 189 201 180 183 193 184\n",
      "  194 209 181 197 208 182 199 204 205 200 196 207 202 206 211 219 212 220\n",
      "  221 217 216 223 218 214 213 215]\n",
      " [ 11  59  42  27  61  31  57  26  30  66  68  72  69  90  65 131 109 130\n",
      "  110 120 142 175 159 157 163 191 210 203 185 222  15  21  39  17  35  28\n",
      "   44  16  20  37  34  32  45   9  24  48  55  14  49  58  54  25  52  47\n",
      "   50  18   5   2  29  33   8  19   6  56  13  22   1  62  63  46   3  43\n",
      "   53  41  38  51  12  64  23  40  36   7  10   0   4  60 105  70  91 100\n",
      "  103 104  82  96  67  79  80  86 107  78  77  85  73  94  71 106 101  93\n",
      "   99  92  83  84  98  97  88  87  81  89  74  95  75 108 102  76 137 124\n",
      "  113 149 150 148 144 145 119 127 143 129 112 117 146 147 133 122 115 140\n",
      "  135 138 134 111 136 128 125 116 118 121 141 126 139 132 123 114 172 179\n",
      "  158 164 153 176 160 165 171 152 169 161 174 173 170 155 167 162 168 154\n",
      "  177 151 178 156 166 184 187 186 192 180 182 195 198 183 199 190 194 181\n",
      "  193 188 202 200 196 197 201 189 208 204 206 207 211 209 205 218 220 214\n",
      "  215 216 217 213 212 219 223 221]]\n"
     ]
    }
   ],
   "source": [
    "P_inis = permu_groups_capa1_anchors_knwn(L_ini, A, start_groups,groups_ini, Anchors, grupos_extra) \n",
    "P_inis = P_inis.astype(int)\n",
    "P_ini_0 = (P_inis[0,:,:]).copy()#\n",
    "P_inv_ini_0 = (P_inis[1,:,:]).copy()\n",
    "print('*************************')\n",
    "print(P_ini_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea5703",
   "metadata": {},
   "source": [
    "## Temperatures\n",
    "\n",
    "We are permorfing a Parallel tempering Markov Chain MonteCarlo\n",
    "\n",
    "We run our MCMC at difference temperatures (proposing changes between them), and we will sample at temper = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28c07022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas: [0.86260878 0.88101504 0.89981405 0.91901419 0.93862401 0.95865228\n",
      " 0.9791079  1.         1.0213379  1.0431311  1.06538932 1.08812249\n",
      " 1.11134073 1.1350544  1.15927407]\n"
     ]
    }
   ],
   "source": [
    "# Temperature distributin\n",
    "beta_o = 1.03\n",
    "total = 15 # Odd name, in order to have beta = 1\n",
    "b_exp = np.linspace(-5,5,num = total)\n",
    "tempers = beta_o**b_exp # Account for 1/KT, called beta in thermodinamics\n",
    "print('betas:', tempers)\n",
    "N_t = len(tempers)\n",
    "\n",
    "## Inizialitation of the system for each temperature, with the same mappings\n",
    "P_ini_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_ini_t = np.zeros((N_t,K,Nx))\n",
    "L_ini_t = np.zeros((N_t,Nx,Nx)) \n",
    "groups_ini_t = np.zeros((N_t, K, Nx ))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(0,N_t): \n",
    "    P_ini_t[i,:,:] = P_ini_0[:,:].copy()\n",
    "    P_inv_ini_t[i,:,:] = P_inv_ini_0[:,:].copy()\n",
    "    L_ini_t[i,:,:] = L_ini.copy()\n",
    "    groups_ini_t[i,:,:] = groups_ini.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060faab1",
   "metadata": {},
   "source": [
    "# MONTE CARLO FUNCTIONS \n",
    "\n",
    "Probably some functions are easy to optimize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9a0c010",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some functions that numba do not have\n",
    "@njit\n",
    "def concatenate_numba_sinrep(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    no_double = []\n",
    "    for i_b in range(size_b):\n",
    "        if b[i_b] in a:\n",
    "            size_b = size_b-1\n",
    "        else:\n",
    "            no_double.append(b[i_b])\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = no_double\n",
    "    \n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def concatenate_numba(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = b \n",
    "    \n",
    "    return c\n",
    "\n",
    "@njit\n",
    "def sum_numba(S):\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    \n",
    "    suma = 0\n",
    "    for i_s in range(Nx):\n",
    "        suma = suma + sum(S[i_s,:])\n",
    "        \n",
    "    return suma\n",
    "@njit\n",
    "def sum_numba_filas(S): # 2 dimensions\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    suma = np.zeros((Nx))\n",
    "    for i_s in range(Nx):\n",
    "        suma_c = 0 # sum of the column\n",
    "        for i_y in range(Ny):\n",
    "            suma[i_s] = suma_c + S[i_y,i_s] \n",
    "        \n",
    "    return suma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3614df13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def parallel_L_knwn_change(c_parallel,alpha,beta,fijado_f,groups_f, N_groups_f, start_f, end_f,\n",
    "                       A, P_t_f, P_inv_t_f, L_t_f,suma_L, Energy_t_f, ovlp_t_f0, ovlp_t_f1, tempers_f):\n",
    "    \n",
    "    # fijado_f : To let one of the networks fixed or not (If only two networks it doesn't matter)\n",
    "    # c_parallel: counter to change temperatures\n",
    "    # start_f, end,f\n",
    "    # N_groups_f: Number of groups\n",
    "    # groups_f: Directly the ggroup numbeer from the position\n",
    "    \n",
    "    ### Movement:\n",
    "    # 1) Choose one node and see their group (also we can choose a group first)\n",
    "    # 2) Choose another random node inside this group \n",
    "    # 3) Each 4 movements, we propose change the temperatures\n",
    "\n",
    "    N_t = L_t_f.shape[0] # Numbers of tempers\n",
    "    Nx = L_t_f.shape[1] # Numbers of nodes\n",
    "    K = A.shape[0] # Numbers of networks\n",
    "    Edges_sum = K*Nx*Nx\n",
    "   \n",
    "    if (c_parallel <4*Nx): # If not change of temperatures\n",
    "        c_parallel += 1\n",
    "        \n",
    "        #Choose the networks to propose the change (in all temperatures)\n",
    "        if (fijado_f == 1):\n",
    "            m1 = np.random.randint(K-1)+1 #One networks\n",
    "        else:\n",
    "            m1 = np.random.randint(K)    \n",
    "        \n",
    "        for k_nt in range(N_t):            \n",
    "            # 1) Choose a random node (node in A)\n",
    "            v1_mapping = np.random.randint(start_f[0], Nx)\n",
    "            # Inside the group:\n",
    "            grupo = groups_f[k_nt,m1,v1_mapping]\n",
    "            start, end = start_f[grupo], end_f[grupo]\n",
    "            size_group = end - start\n",
    "            todos = size_group \n",
    "            if (size_group > 1): \n",
    "\n",
    "                v2_mapping = np.random.randint(start, end)\n",
    "                while (v2_mapping == v1_mapping):\n",
    "                    v2_mapping = np.random.randint(start, end)\n",
    "\n",
    "                # Nodes in L\n",
    "                v1 = P_t_f[k_nt, m1,v1_mapping]\n",
    "                v2 = P_t_f[k_nt, m1, v2_mapping]\n",
    "\n",
    "\n",
    "                ### Only changes in the specific columns and rows\n",
    "                L_f_v1v2, L_f_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "                L_c_v1v2, L_c_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "\n",
    "                pp_1 = int(P_inv_t_f[k_nt,m1,v2]) # v2_mapping\n",
    "                pp_2 = int(P_inv_t_f[k_nt,m1,v1]) # v1_mapping\n",
    "                \n",
    "                # Changes in the blueprint\n",
    "                L_f_v1v2,L_c_v1v2 , suma_aux = L_wiring_change_filas(m1,L_t_f[k_nt,:,:], A, v1, v2, P_inv_t_f[k_nt,:,:])\n",
    "                L_f_v1v2_old[0,:],L_f_v1v2_old[1,:] = L_t_f[k_nt,v1,:].copy(),L_t_f[k_nt,v2,:].copy()\n",
    "                L_c_v1v2_old[0,:],L_c_v1v2_old[1,:] = L_t_f[k_nt,:,v1].copy(),L_t_f[k_nt,:,v2].copy()\n",
    "                \n",
    "                # Parameters to change\n",
    "                Edges_L = K*(suma_L[k_nt] + suma_aux)\n",
    "                Edges_NoL = Edges_sum - Edges_L\n",
    "                ovl_0_new, ovl_1_new = overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2 ,A,P_inv_t_f[k_nt,:,:], v1,v2, pp_1, pp_2)\n",
    "                overlap_0,overlap_1 = ovlp_t_f0[k_nt] + ovl_0_new, ovlp_t_f1[k_nt] + ovl_1_new\n",
    "                Energy_bucle = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "                dE_sampler = Energy_bucle - Energy_t_f[k_nt]\n",
    "                dE_t = dE_sampler\n",
    "\n",
    "\n",
    "                ### UPDATE\n",
    "                if (dE_t < 0):\n",
    "                    \n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:].copy(),L_f_v1v2[1,:].copy()\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:].copy(),L_c_v1v2[1,:].copy()\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "                elif (np.random.rand() < np.exp(-dE_t*tempers_f[k_nt])):\n",
    "\n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:].copy(),L_f_v1v2[1,:].copy()\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:].copy(),L_c_v1v2[1,:].copy()\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "    else: # Change in temperatures\n",
    "        c_parallel = 0 \n",
    "        \n",
    "        mt1 = np.random.randint(N_t)  #temper 1\n",
    "        mt2 =  np.random.randint(N_t) #temper 2\n",
    "        while (mt1 == mt2):\n",
    "            mt2 = np.random.randint(N_t)\n",
    "\n",
    "        Energy_1 = Energy_t_f[mt1]\n",
    "        Energy_2 = Energy_t_f[mt2] \n",
    "\n",
    "        dE_parallel = -(tempers_f[mt1]-tempers_f[mt2])*(Energy_1-Energy_2)\n",
    "        if (dE_parallel <0):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            # 1 --> 2\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "\n",
    "            # 2 --> 1\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "        elif (np.random.rand() < np.exp(-dE_parallel)):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            # 1 --> 2\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "\n",
    "            # 2 --> 1\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "    return c_parallel, P_t_f, P_inv_t_f,Energy_t_f, ovlp_t_f0, ovlp_t_f1, L_t_f, suma_L, groups_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acdad61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2,A_f, P_inv_old, i_change, j_change,pp1, pp2): \n",
    "\n",
    "    Nx = L_f_v1v2_old.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0_new , ovlp_1_new = 0,0\n",
    "    ovlp_0_old , ovlp_1_old = 0,0\n",
    "    ovlp_0_dif, ovlp_1_dif = 0,0\n",
    "  \n",
    "    #old and new: changes and mapping changes\n",
    "    changes = np.array([i_change, j_change], dtype = np.int32)\n",
    "    changes_p = np.array([pp1, pp2], dtype = np.int32)  \n",
    "    changes_old = np.array([j_change, i_change], dtype = np.int32)\n",
    "    changes_p_old = np.array([pp2, pp1], dtype = np.int32)\n",
    "    \n",
    "    for i_k in range(K):\n",
    "        for i_chan,change in enumerate(changes):\n",
    "            for i_x in range(Nx):\n",
    "                if (i_k != m1): # Only changes in the networks m1\n",
    "                    p_f = int(P_inv_old[i_k,change])\n",
    "                    p_c = int(P_inv_old[i_k,i_x])\n",
    "                    p_old, p_old_c = p_f, p_c\n",
    "                \n",
    "                else:\n",
    "                    p_f = changes_p[i_chan]\n",
    "                    p_old = changes_p_old[i_chan]\n",
    "                    if (i_x == i_change):\n",
    "                        p_c = pp1\n",
    "                        p_old_c = pp2\n",
    "                    elif(i_x == j_change):\n",
    "                        p_c = pp2\n",
    "                        p_old_c = pp1\n",
    "                    else: # Only changes in the nodes i,j\n",
    "                        p_c = int(P_inv_old[i_k, i_x])\n",
    "                        p_old_c = p_c\n",
    "\n",
    "                ## rows\n",
    "                valor_L_old, valor_A_old = L_f_v1v2_old[i_chan,i_x], A_f[i_k,p_old,p_old_c]   \n",
    "                valor_L_new, valor_A_new = L_f_v1v2[i_chan,i_x], A_f[i_k,p_f,p_c]\n",
    "                ## columns\n",
    "                valor_L_old_c, valor_A_old_c = 0,0\n",
    "                valor_L_new_c, valor_A_new_c = 0,0\n",
    "                column = 0\n",
    "                if (i_x not in changes):\n",
    "                    column = 1\n",
    "                    valor_L_old_c, valor_A_old_c = L_c_v1v2_old[i_chan,i_x],A_f[i_k,p_old_c, p_old]\n",
    "                    valor_L_new_c, valor_A_new_c = L_c_v1v2[i_chan,i_x], A_f[i_k,p_c,p_f]\n",
    "\n",
    "                ovlp_1_old = ovlp_1_old + valor_L_old*valor_A_old + valor_L_old_c*valor_A_old_c*column\n",
    "                ovlp_0_old = ovlp_0_old + (1-valor_L_old)*(1-valor_A_old) + (1-valor_L_old_c)*(1-valor_A_old_c)*column\n",
    "                \n",
    "                ovlp_1_new = ovlp_1_new + valor_L_new*valor_A_new + valor_L_new_c*valor_A_new_c*column\n",
    "                ovlp_0_new = ovlp_0_new + (1-valor_L_new)*(1-valor_A_new) + (1-valor_L_new_c)*(1-valor_A_new_c)*column\n",
    "                \n",
    "    ovlp_1_def = ovlp_1_new - ovlp_1_old\n",
    "    ovlp_0_def = ovlp_0_new- ovlp_0_old\n",
    "   \n",
    "    return ovlp_0_def, ovlp_1_def\n",
    "@jit(nopython=True)\n",
    "def L_wiring_change_filas(m1,L_old,A_f, i_change, j_change, P_inv_old):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    K = A_f.shape[0] \n",
    "    \n",
    "    L_new_f = L_old.copy()\n",
    "    L_f_v1v2,L_c_v1v2  = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "    \n",
    "    ## changes\n",
    "    changes = np.array([i_change, j_change])\n",
    "    changes_new = np.array([j_change, i_change])\n",
    "    \n",
    "    ## Old values\n",
    "    suma_old =(np.sum(L_old[i_change,:]) + np.sum(L_old[j_change,:]) + np.sum(L_old[:,i_change]) + np.sum(L_old[:,j_change]))-L_old[i_change,j_change]-L_old[j_change,j_change]-L_old[i_change,i_change]-L_old[j_change,i_change]\n",
    "    \n",
    "    ## New row and column\n",
    "    L_new_f[i_change,:], L_new_f[j_change,:], L_new_f[:,i_change], L_new_f[:,j_change] = np.zeros(Nx),np.zeros(Nx),np.zeros(Nx),np.zeros(Nx)\n",
    "    \n",
    "\n",
    "    suma_1 = 0\n",
    "    ## ROWS\n",
    "    for i_i,i_chan in enumerate(changes): #Only looking at the \n",
    "        for i_x in range(Nx):\n",
    "            if (i_x not in changes): # The rest of nodes\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    \n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "\n",
    "            else: # The nodes that change\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                        \n",
    "                        if (i_x == changes_new[0]):\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[1]])\n",
    "                        else:\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[0]])\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                        p2_2 = int(P_inv_old[k,i_x])\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "\n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "                    \n",
    "            valor_lnew_2=1/K*  L_f_v1v2[i_i,i_x]\n",
    "            L_f_v1v2[i_i,i_x] = round( valor_lnew_2 )\n",
    "            \n",
    "                    \n",
    "    ## COLUMNS \n",
    "    for j_j,j_chan in enumerate(changes):\n",
    "        for i_x in range(Nx):\n",
    "            changes_x = 0\n",
    "            if (i_x not in changes):\n",
    "                for k in range(K):\n",
    "                    \n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[j_j]\n",
    "                    else:\n",
    "                        chan_new = changes[j_j]\n",
    "                        \n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    L_c_v1v2[j_j,i_x] += A_f[k,p2_2,p1_2]\n",
    "                \n",
    "                valor_lnew_2=1/K* L_c_v1v2[j_j,i_x]\n",
    "                L_c_v1v2[j_j,i_x] = round( valor_lnew_2)\n",
    "\n",
    "                    \n",
    "            else: # the changes are the same as the columns\n",
    "                changes_x = 1\n",
    "                if (i_x == j_chan):\n",
    "                    L_c_v1v2[j_j,i_x] =  L_f_v1v2[j_j,i_x]\n",
    "                else:\n",
    "                    i_x_inv = changes[j_j]\n",
    "                    if (j_j  == 0):\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[1,i_x_inv]\n",
    "\n",
    "                    else:\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[0,i_x_inv]\n",
    "           \n",
    "    suma_new = np.sum(L_f_v1v2[0,:]) + np.sum(L_f_v1v2[1,:]) + np.sum(L_c_v1v2[0,:]) + np.sum(L_c_v1v2[1,:])-L_c_v1v2[0,j_change]-L_c_v1v2[0,i_change]-L_c_v1v2[1,j_change]-L_c_v1v2[1,i_change]\n",
    "    suma_1 = suma_new - suma_old\n",
    "    return L_f_v1v2,L_c_v1v2, suma_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bc917",
   "metadata": {},
   "source": [
    "# Running MonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "078591b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fijado = 0 # To maintain fix the first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a694a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy with the reference mapping: 16019.663954670905\n",
      "overlap_0: 192861 /overlap_1: 4653\n",
      "%Overlaps: 98.41059470663265 %\n"
     ]
    }
   ],
   "source": [
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i]=i \n",
    "        P_inv_new[k,i]=i            \n",
    "L_new = np.zeros((Nx,Nx)) \n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) # Los edges=1 que tiene la matriz A\n",
    "Edges_NoL = Edges_sum - Edges_L #Los edges=0 que tiene la matriz A\n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "print('Energy with the reference mapping:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "591d3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy with the reference mapping: 16019.663954670905\n",
      "overlap_0: 192861 /overlap_1: 4653\n",
      "%Overlaps: 98.41059470663265 %\n",
      "\n",
      "Initial energy with L = A[0]: 64.73048223888327\n",
      "\n",
      "Energy with L_wiring: 31025.37593389148\n",
      "overlaps 0: 193220 1: 276\n",
      "%Overlaps: 96.40864158163265 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 10/10 [00:27<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (after compilation) = 27.541791200637817\n",
      "Energy final: [29854.52938331 29803.97298102 29814.78726386 29807.21153981\n",
      " 29873.94154928 29905.41954317 29888.08857244 29946.51913924\n",
      " 29838.09337522 29797.4673796  29851.26031062 29910.10786708\n",
      " 30000.52189918 29723.92909959 29773.60397418] /Computed final: [29854.52938331 29803.97298102 29814.78726386 29807.21153981\n",
      " 29873.94154928 29905.41954317 29888.08857244 29946.51913924\n",
      " 29838.09337522 29797.4673796  29851.26031062 29910.10786708\n",
      " 30000.52189918 29723.92909959 29773.60397418]\n",
      "overlaps_0: 193085 overlap_1: 717 %overlaps: 96.56110491071429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed( random.randint(1,1999))\n",
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i]=i \n",
    "        P_inv_new[k,i]=i            \n",
    "L_new = np.zeros((Nx,Nx))\n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) # edges=1 in A\n",
    "Edges_NoL = Edges_sum - Edges_L # edges=0 in A\n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "print('Energy with the reference mapping:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n",
    "\n",
    "\n",
    "# VARIABLE USING INITIAL CONDITIONS\n",
    "P_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_t = np.zeros((N_t,K,Nx))\n",
    "L_t = np.zeros((N_t,Nx, Nx))\n",
    "Energy_t, Energy_ini_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "Edges_L_t, Edges_NoL_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "groups_t = np.zeros((N_t, K, Nx))\n",
    "ovlp_ini0_t = np.zeros((N_t)) + ovlp_ini0\n",
    "ovlp_ini1_t = np.zeros((N_t)) + ovlp_ini1\n",
    "ovlp_ini0_t, ovlp_ini1_t = ovlp_ini0_t.astype(int), ovlp_ini1_t.astype(int)\n",
    "ovlp_t0, ovlp_t1 = np.zeros((N_t)) + ovlp_ini0, np.zeros((N_t)) + ovlp_ini1\n",
    "P_t = (P_ini_t).copy()\n",
    "P_inv_t = (P_inv_ini_t).copy()\n",
    "L_t = (L_ini_t).copy()\n",
    "groups_t = groups_ini_t.copy()\n",
    "#Integer variables\n",
    "ovlp_t0, ovlp_t1 = ovlp_t0.astype(int), ovlp_t1.astype(int)\n",
    "P_t = P_t.astype(int)\n",
    "P_inv_t = P_inv_t.astype(int)\n",
    "L_t = L_t.astype(int)\n",
    "groups_t = groups_t.astype(int)\n",
    "\n",
    "## Initial energy with L = A[0]\n",
    "Edges_L = K*sum(sum(L_ini))\n",
    "Edges_NoL = Edges_sum - Edges_L            \n",
    "Energy_ini = hamiltonian_prob(Edges_NoL, Edges_L, ovlp_ini0, ovlp_ini1 ,alpha, beta)\n",
    "Energy_ini_t = np.zeros((N_t))+ Energy_ini \n",
    "print()\n",
    "print('Initial energy with L = A[0]:', Energy_ini)\n",
    "print()\n",
    "\n",
    "\n",
    "#### Now the Blueprint is averaged\n",
    "for k_nt in range(N_t):\n",
    "    L_t[k_nt,:,:] =  L_wiring(A, P_inv_t[k_nt,:,:])\n",
    "    Edges_L_t[k_nt] = K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL_t[k_nt] = Edges_sum - Edges_L_t[k_nt]\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_t[k_nt] = hamiltonian_prob(Edges_NoL_t[k_nt], Edges_L_t[k_nt], overlap_0, overlap_1,alpha, beta)\n",
    "    ovlp_t0[k_nt], ovlp_t1[k_nt] = overlap_0, overlap_1\n",
    "print('Energy with L_wiring:', Energy_t[0]) \n",
    "print('overlaps 0:', ovlp_t0[0], '1:', ovlp_t1[0])\n",
    "print('%Overlaps:',100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n",
    "Energy_ini_wiring = Energy_t.copy()\n",
    "suma_L_t = np.zeros(N_t)\n",
    "for k_nt in range(N_t):\n",
    "    suma_L_t[k_nt] = sum_numba(L_t[k_nt,:,:])\n",
    "\n",
    "\n",
    "### MONTE CARLO\n",
    "# Parameters\n",
    "PasosMC = 10#000\n",
    "Long_corr = 500\n",
    "Pasos_corr = 5000\n",
    "Pasos_store = int((PasosMC - Pasos_corr)/Long_corr)\n",
    "if (Pasos_store<0):\n",
    "    Pasos_store = 0\n",
    "steps_middle_0 = 500\n",
    "steps_middle_1 = 1000\n",
    "    \n",
    "# Variables to store    \n",
    "energies_pasos = np.zeros((N_t,PasosMC))\n",
    "energies_pasos[:,0] = Energy_ini_wiring\n",
    "count_parallel, count_unl = 0, 0\n",
    "P_store = np.zeros((Pasos_store,N_t, K, Nx))\n",
    "groups_store = np.zeros((Pasos_store, N_t,K,Nx))\n",
    "Energy_store = np.zeros((Pasos_store, N_t))\n",
    "L_store = np.zeros((Pasos_store,N_t, Nx, Nx))\n",
    "P_intermediate_shot = np.zeros((2,N_t,K,Nx))\n",
    "E_intermediate_shot = np.zeros((2,N_t))\n",
    "\n",
    "\n",
    "#######################################\n",
    "start = time.time()\n",
    "count_parallel, count_long, i_long = 0,0,0\n",
    "for i_mc in tqdm(range(0,PasosMC)):\n",
    "## Starting to store sampling configurations\n",
    "    if (i_mc > Pasos_corr):\n",
    "        count_long += 1\n",
    "        if (count_long == Long_corr):\n",
    "            count_long = 0\n",
    "            P_store[i_long,:,:,:] = P_t.copy()\n",
    "            Energy_store[i_long,:] = Energy_t.copy()\n",
    "            L_store[i_long,:,:,:] = L_t.copy()\n",
    "            groups_store[i_long, :,:] = groups_t.copy()\n",
    "            i_long += 1\n",
    "            print('Step', i_mc, 'Energy (temper = 1):', Energy_t[4])\n",
    "    \n",
    "    ## Store transient configurations\n",
    "    if (i_mc == steps_middle_0 ):\n",
    "        P_intermediate_shot[0,:,:,:] = P_t.copy()\n",
    "        E_intermediate_shot[0,:] = Energy_t.copy()\n",
    "    if (i_mc == steps_middle_1 ):\n",
    "        P_intermediate_shot[1,:,:,:] = P_t.copy()\n",
    "        E_intermediate_shot[1,:] = Energy_t.copy()\n",
    "\n",
    "\n",
    "    energies_pasos[:, i_mc] = Energy_t[:]\n",
    "    for i_micro in range(Nx):\n",
    "\n",
    "        count_parallel,P_t, P_inv_t, Energy_t, ovlp_t0, ovlp_t1, L_t,suma_L_t, groups_t = parallel_L_knwn_change( count_parallel,alpha,beta,fijado,groups_t,n_groups, start_anchor, \n",
    "                                                                                                 end_anchor, A, P_t, P_inv_t, L_t,suma_L_t, Energy_t, ovlp_t0, \n",
    "                                                                                                 ovlp_t1, tempers)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                                                                                                         \n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))  \n",
    "\n",
    "## Final energy\n",
    "Energy_calculada = np.zeros((N_t))\n",
    "for k_nt in range(N_t):\n",
    "    Edges_L= K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL = Edges_sum - Edges_L\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_calculada[k_nt] = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "    \n",
    "print('Energy final:', Energy_t, '/Computed final:', Energy_calculada) \n",
    "print('overlaps_0:', ovlp_t0[0], 'overlap_1:', ovlp_t1[0], '%overlaps:', 100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d3fdfc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Voy a ver si el problema es solo group_f o las propias permutaciones\n",
    "P_ver = P_t[2,1,:].copy()\n",
    "P_inv_ver = np.zeros((Nx))\n",
    "for i_inv in range(0,Nx):\n",
    "    for j_inv in range(0,Nx):\n",
    "        if (P_ver[i_inv] == j_inv):\n",
    "            P_inv_ver[ j_inv]=i_inv\n",
    "            \n",
    "P_inv_ori = P_inv_t[2,1,:].copy()\n",
    "print(sum(P_inv_ori - P_inv_ver))\n",
    "print(sum(np.sort(P_t[0, m1,:])- np.arange(Nx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ef2973c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x=np.arange(PasosMC)\n",
    "for k_nt in range(0,N_t):\n",
    "    energies_pasos_temper = energies_pasos[k_nt,:] \n",
    "    plt.plot(x,energies_pasos_temper,'.',label='%s temper' % tempers[k_nt])\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('Energy per node')\n",
    "# plt.legend()\n",
    "plt.savefig('Ener_Anchors_k4.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2b9b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Energy_t[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bcbbaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a construir un diccionario para guardar todo\n",
    "d_store={}\n",
    "string = \"celegant_k4_anchor15_paper_4.pickle\"\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"P_inter\"] = P_intermediate_shot\n",
    "d_store[\"E_inter\"] = E_intermediate_shot\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "d_store[\"groups\"] = groups_store\n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "prueba = pickle.load(open(string, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b48e65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab9a160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
