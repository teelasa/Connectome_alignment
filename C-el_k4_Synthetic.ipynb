{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69eba05",
   "metadata": {},
   "source": [
    "# Parallel Tempering\n",
    "\n",
    "In the following code, we created four networks using the generative model with probability of error in copying links and no links. We set the blueprint as A2, because is the one with the bigger number of connections\n",
    "\n",
    "In this notebook we are not working with weighted networks, only with the presence or not of a connection (Binary adjacency matrices).\n",
    "\n",
    "Blablabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefb8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numba import jit, njit\n",
    "from numba.types import bool_, int_, float32\n",
    "from math import comb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0ae0a",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c848c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read: 0 size (227, 183)\n",
      "Read: 1 size (227, 183)\n",
      "Read: 2 size (227, 183)\n",
      "Read: 3 size (227, 183)\n",
      "Read: 4 size (227, 183)\n",
      "Read: 5 size (227, 183)\n",
      "Read: 6 size (227, 183)\n",
      "Read: 7 size (227, 183)\n"
     ]
    }
   ],
   "source": [
    "### Open the files\n",
    "tablas = 8\n",
    "n_grupo = 4\n",
    "\n",
    "d = {}\n",
    "D = \"Dataset\"\n",
    "for i in range(0,tablas):\n",
    "    d[\"group\" + str(i)] = pd.read_excel(\"datasets.ods\", sheet_name=D+str(i+1))\n",
    "    print('Read:',i, 'size', d[\"group\" + str(i)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae59472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hipermatrix M with the data (Only the synapses) \n",
    "rows = d[\"group\" + str(i)].shape[0] - 3\n",
    "columns = d[\"group\" + str(i)].shape[1] - 3\n",
    "\n",
    "M = np.zeros((tablas,rows,columns))\n",
    "for i in range(0, tablas):\n",
    "    Data = d['group' + str(i)]\n",
    "    M[i,:,:] = Data.iloc[3:,3:]\n",
    "    \n",
    "## Since we work with same number of nodes, we want them equal and square (zeros when no connections)\n",
    "M_square = np.zeros((tablas, rows, rows))\n",
    "M_square[:,:, 0:columns] = M[:,:,:]\n",
    "\n",
    "## Binarization: No weights\n",
    "#Lo queremos BINARIO, ignorando su peso (Luego pensar cómo se haría con el peso)\n",
    "M_square_bin = np.zeros((tablas,rows,rows))\n",
    "for i in range(tablas):\n",
    "    for j in range(rows):\n",
    "        for k in range(columns):\n",
    "            if (M[i,j,k] >= 1):\n",
    "                M_square_bin[i,j,k] = 1\n",
    "                \n",
    "Nx = rows # Number of nodes (we imposed rows == columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb1e46",
   "metadata": {},
   "source": [
    "### GROUP INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5e011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grupos: Sensory, Inter, Motor, Modulatory, Muscle, Other\n",
      "SIZE GROUPS: [65 44 42 29 32 12]\n",
      "***********************************\n",
      "First node in each group [  0  65 109 151 180 212]\n",
      "Last node in each group [ 65 109 151 180 212 224]\n"
     ]
    }
   ],
   "source": [
    "# Groups from the database\n",
    "Sensory = 69-5 #0\n",
    "Inter = 113-70 # 1\n",
    "Motor = 155-114 #2\n",
    "Modulatory = 184-156 #3\n",
    "Muscle = 216-185 #4 \n",
    "Others = 228-217 #5\n",
    "\n",
    "size_groups = np.array([Sensory, Inter, Motor, Modulatory, Muscle, Others]) + 1 #Started in 0\n",
    "n_groups = len(size_groups)\n",
    "start_groups = np.zeros(n_groups)\n",
    "end_groups = np.zeros(n_groups)\n",
    "\n",
    "\n",
    "print('grupos: Sensory, Inter, Motor, Modulatory, Muscle, Other')\n",
    "print('SIZE GROUPS:', size_groups)\n",
    "\n",
    "\n",
    "#Para evitar trabajar con diccionarios (por NUMBA), vamos a hacer matrices \n",
    "# Cada matriz tiene el tamaño de la de mayor, pero luego las vamos cortando\n",
    "rows_g, columns_g = size_groups.max(), size_groups.max()\n",
    "\n",
    "size_suma = 0\n",
    "start_groups[0] = 0\n",
    "for i in range(n_groups):\n",
    "    size = size_groups[i]\n",
    "    if (i != n_groups-1):\n",
    "        start_groups[i+1] = int(size_suma + size)\n",
    "    size_suma = size_suma + (size) \n",
    "#end\n",
    "for i in range(0,n_groups):\n",
    "    if (i!= n_groups-1):\n",
    "        end_groups[i] = start_groups[i+1]\n",
    "    else:\n",
    "        end_groups[i] = Nx\n",
    "start_groups = start_groups.astype(int)\n",
    "end_groups = end_groups.astype(int)\n",
    "\n",
    "print('***********************************')\n",
    "print('First node in each group', start_groups)\n",
    "print('Last node in each group', end_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955c46f",
   "metadata": {},
   "source": [
    "## ENERGY FUNCTIONS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90620ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta):\n",
    "\n",
    "    A_1 = overlap_1 + alpha\n",
    "    B_1 = (Edges_L - overlap_1 + beta)\n",
    "    C_1 = Edges_L + alpha + beta\n",
    "    \n",
    "    A_0 = overlap_0 + alpha\n",
    "    B_0 = (Edges_NoL - overlap_0 + beta)\n",
    "    C_0 = Edges_NoL + alpha + beta\n",
    "    \n",
    "    #  [ math.lgamma(n+1) == log(n!) ]\n",
    "    H1 = math.lgamma(A_1)+ math.lgamma(B_1) - math.lgamma(C_1) \n",
    "    H0 = math.lgamma(A_0)+ math.lgamma(B_0) - math.lgamma(C_0) \n",
    "    \n",
    "    H = -(H1 + H0)\n",
    "    return H\n",
    "    \n",
    "    \n",
    "@jit(nopython=True)\n",
    "def overlap_total_prob(L_f, A_f, P_inv_f):\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0 = np.zeros((K))\n",
    "    ovlp_1 = np.zeros((K))\n",
    "    for k in range(0,K):\n",
    "        for f in range(0,Ny): \n",
    "            for c in range(0,Nx):\n",
    "                p_f=int(P_inv_f[k,f])\n",
    "                p_c=int(P_inv_f[k,c])  \n",
    "                \n",
    "                valor_L, valor_A = L_f[f,c], A_f[k,p_f,p_c]\n",
    "                \n",
    "                ovlp_0[k] = ovlp_0[k] + (1-valor_L)*(1-valor_A )\n",
    "                ovlp_1[k] = ovlp_1[k] + valor_L*valor_A\n",
    "                \n",
    "                \n",
    "    ovlp_1 = int(sum(ovlp_1))\n",
    "    ovlp_0 = int(sum(ovlp_0))\n",
    "    return ovlp_0, ovlp_1\n",
    "\n",
    "\n",
    "@jit(nopython=True) # The blueprint is the average of the observations (taking into account the mapping)  \n",
    "def L_wiring(A_f, P_inv_f):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "    L_new_f = np.zeros((Nx,Ny))\n",
    "    \n",
    "    for i in range(0,Nx):\n",
    "        for j in range(0,Ny):\n",
    "            for k in range(0,K):\n",
    "        \n",
    "                p1 = int(P_inv_f[k,i]) # Mapping of the observations\n",
    "                p2 = int(P_inv_f[k,j]) # Mapping of the observations\n",
    "                L_new_f[i,j] += A_f[k,p1,p2]\n",
    "            valor_lnew=1/K* L_new_f[i,j]\n",
    "            L_new_f[i,j] = round( valor_lnew ) \n",
    "            # If valor_lnew = 0, L=0 (we could establish L=1, but it is more probable to not have a connection)\n",
    "    \n",
    "    return L_new_f\n",
    "\n",
    "\n",
    "#### Some algorithm for sorting\n",
    "@jit(nopython=True)\n",
    "def partition(array,  etiquetas, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if array[i] < array[begin]:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "            etiquetas[i], etiquetas[pivot] = etiquetas[pivot], etiquetas[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    etiquetas[pivot], etiquetas[begin] = etiquetas[begin], etiquetas[pivot] \n",
    "\n",
    "    return pivot\n",
    "@jit(nopython=True)\n",
    "def quicksort(array, etiquetas, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    if begin >= end: #To end\n",
    "        return\n",
    "    pivot = partition(array,  etiquetas, begin, end)\n",
    "    \n",
    "    #Order right and left\n",
    "    quicksort(array, etiquetas, begin, pivot-1)\n",
    "    quicksort(array,  etiquetas, pivot+1, end)\n",
    "    \n",
    "@njit \n",
    "# We inizialise the algorithm sorting by node degree, but also taking into account the group labels\n",
    "def permu_groups(L_f, A_f, start_f): \n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    N_groups = len(start_f)\n",
    "    \n",
    "    \n",
    "    # Mappings\n",
    "    P_f = np.zeros((K,Nx)) #Mapping from L to A\n",
    "    P_inv_f = np.zeros((K,Nx)) #Mapping from A to L\n",
    "    P_new = np.zeros((K,Nx))\n",
    "    \n",
    "    # First we order the blueprint and after the observations\n",
    "    # Blueprint:\n",
    "    orden_L=np.zeros((Nx))\n",
    "    for i in range(Nx):\n",
    "        b=np.nonzero(L_f[i,:])\n",
    "        orden_L[i] = b[0].size\n",
    "        \n",
    "    array_L = np.arange(Nx) #For the labels \n",
    "    quicksort(orden_L, array_L)\n",
    "    \n",
    "    # Now according to the group label\n",
    "    array_L_labels = np.zeros((Nx))\n",
    "    group_number = np.zeros((N_groups))\n",
    "    for i in range(Nx):\n",
    "        n_type = 0\n",
    "        #Group\n",
    "        while ( (array_L[i] >= start_f[n_type]) and (n_type < N_groups)):\n",
    "            n_type += 1\n",
    "       \n",
    "        grupo = int(n_type-1)\n",
    "        g = int(start_f[grupo])\n",
    "        array_L_labels[g + int(group_number[grupo])] = array_L[i]\n",
    "        group_number[grupo] += 1\n",
    "\n",
    "    #Observations: \n",
    "    for i in range(0,K):\n",
    "        orden_A = np.zeros((Nx))\n",
    "        for i_orden in range(Nx):\n",
    "            b = np.nonzero(A_f[i,i_orden,:])\n",
    "            orden_A[i_orden] = b[0].size\n",
    "\n",
    "        array_A = np.arange(Nx) #For the labels \n",
    "        quicksort(orden_A, array_A)\n",
    "            \n",
    "        # Now according to the group label\n",
    "        array_A_labels = np.zeros((Nx))\n",
    "        group_number = np.zeros((N_groups))\n",
    "        \n",
    "        for i_g in range(Nx):\n",
    "            n_type = 0\n",
    "            while ( (array_A[i_g] >= start_f[n_type]) and (n_type < N_groups) ):\n",
    "                n_type += 1\n",
    "\n",
    "            grupo = int(n_type-1)\n",
    "            g = int(start_f[grupo])\n",
    "            array_A_labels[ g + int(group_number[grupo])] = array_A[i_g]\n",
    "            group_number[grupo] += 1\n",
    "    \n",
    "\n",
    "    # Now ordered together both label array  array_L = [0,1,2,3...]\n",
    "        array_A_labels = array_A_labels[np.argsort(array_L_labels)]\n",
    "        P_f[i,:] = array_A_labels\n",
    "        \n",
    "        for i_inv in range(0,Nx):\n",
    "            for j_inv in range(0,Ny):\n",
    "                if (P_f[i,i_inv] == j_inv):\n",
    "                    P_inv_f[i, j_inv]=i_inv\n",
    "    \n",
    "    P_todo = np.zeros((2,K,Nx))\n",
    "    P_todo[0,:,:] = P_f.copy() \n",
    "    P_todo[1,:,:] = P_inv_f.copy()\n",
    "\n",
    "    return P_todo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2881b5b",
   "metadata": {},
   "source": [
    "## INITIAL CONDITIONS\n",
    "\n",
    "We will align the four networks from A2. They have the same number of errors iin links and no links (so the probability of copying bad a no-link is smaller)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ce360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [18 64 26 48 25 10 45 57 38 58]\n",
      " [61 58 16 39  4 15  6 35 38 56]\n",
      " [37 61  0 63 27 28  1 14 41 17]]\n"
     ]
    }
   ],
   "source": [
    "Nx = rows # Nodes\n",
    "K = 4 # Number of networks\n",
    "alpha,beta = 5,2 # Values for the beta prior distribution \n",
    "\n",
    "\n",
    "Edges = Nx*Nx \n",
    "micropasos = Edges*K #Microsteps for each MCMC\n",
    "A = np.zeros((K,Nx,Nx))\n",
    "\n",
    "##Copying process\n",
    "np.random.seed(np.random.randint(1,1000))\n",
    "e_error = 327 # Miscopied edges\n",
    "z_error = 327 # Miscopied no-edges\n",
    "L_original = M_square_bin[-1, :,:] # A2 as the blueprint in  the generative model\n",
    "for m1 in range(K):\n",
    "    A[m1,:,:] = L_original.copy()\n",
    "    A_array = np.reshape(A[m1,:,:], (Nx*Nx))\n",
    "    # Error copy edge\n",
    "    for i_e in range(e_error):\n",
    "        posi = np.random.randint(len( np.where(A_array == 1)[0] ))\n",
    "        A_array[posi] = 0\n",
    "    # Error copy zero\n",
    "    for i_z in range(z_error):\n",
    "        posi = np.random.randint(len(np.where(A_array == 0)[0]))\n",
    "        A_array[posi] = 1\n",
    "    A[m1,:,:] = np.reshape(A_array, (Nx,Nx))\n",
    "    \n",
    "d_store={}\n",
    "string = \"Matriz_epochs_A.pickle\"\n",
    "d_store[\"A\"] = A\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "prueba = pickle.load(open(string, \"rb\"))\n",
    "####################################\n",
    "\n",
    "## INITIALIZATION ##\n",
    "\n",
    "L_ini = np.zeros((Nx,Nx))\n",
    "P_ini_0 = np.zeros((K,Nx))\n",
    "P_inv_ini_0 = np.zeros((K,Nx))\n",
    "\n",
    "# We inizialize with the Blueprint = L2\n",
    "L_ini = (A[0,:,:]).copy()\n",
    "\n",
    "groups_ini = np.zeros((K,Nx)) #Groups label\n",
    "for m1 in range(K):\n",
    "    for i_g in range(n_groups):\n",
    "        start = start_groups[i_g]\n",
    "        end = end_groups[i_g]\n",
    "        groups_ini[m1, start:end] = i_g\n",
    "        \n",
    "## Overlaps\n",
    "ovlp_ini0, ovlp_ini1 = overlap_total_prob(L_ini,A,P_inv_ini_0)\n",
    "\n",
    "        \n",
    "# Inizialization according to node-degree (taking into account group labels)\n",
    "P_inis = permu_groups(L_ini, A, start_groups)\n",
    "P_inis = P_inis.astype(int)\n",
    "P_ini_0 = (P_inis[0,:,:]).copy() # Mapping L to A\n",
    "P_inv_ini_0 = (P_inis[1,:,:]).copy() # Mapping A to L\n",
    "print('*************************')\n",
    "print(P_ini_0[:,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea5703",
   "metadata": {},
   "source": [
    "## Temperatures\n",
    "\n",
    "We are permorfing a Parallel tempering Markov Chain MonteCarlo\n",
    "\n",
    "We run our MCMC at difference temperatures (proposing changes between them), and we will sample at temper = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c07022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas: [0.86260878 0.88101504 0.89981405 0.91901419 0.93862401 0.95865228\n",
      " 0.9791079  1.         1.0213379  1.0431311  1.06538932 1.08812249\n",
      " 1.11134073 1.1350544  1.15927407]\n"
     ]
    }
   ],
   "source": [
    "# Temperature distributin\n",
    "beta_o = 1.03\n",
    "total = 15 # Odd name, in order to have beta = 1\n",
    "b_exp = np.linspace(-5,5,num = total)\n",
    "tempers = beta_o**b_exp # Account for 1/KT, called beta in thermodinamics\n",
    "print('betas:', tempers)\n",
    "N_t = len(tempers)\n",
    "\n",
    "## Inizialitation of the system for each temperature, with the same mappings\n",
    "P_ini_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_ini_t = np.zeros((N_t,K,Nx))\n",
    "L_ini_t = np.zeros((N_t,Nx,Nx)) \n",
    "groups_ini_t = np.zeros((N_t, K, Nx ))\n",
    "\n",
    "for i in range(0,N_t): \n",
    "    P_ini_t[i,:,:] = P_ini_0[:,:].copy()\n",
    "    P_inv_ini_t[i,:,:] = P_inv_ini_0[:,:].copy()\n",
    "    L_ini_t[i,:,:] = L_ini.copy()\n",
    "    groups_ini_t[i,:,:] = groups_ini.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060faab1",
   "metadata": {},
   "source": [
    "# MONTE CARLO FUNCTIONS \n",
    "\n",
    "Probably some functions are easy to optimize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84568c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some functions that numba do not have\n",
    "@njit\n",
    "def concatenate_numba_sinrep(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    no_double = []\n",
    "    for i_b in range(size_b):\n",
    "        if b[i_b] in a:\n",
    "            size_b = size_b-1\n",
    "        else:\n",
    "            no_double.append(b[i_b])\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = no_double\n",
    "    \n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def concatenate_numba(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = b \n",
    "    \n",
    "    return c\n",
    "\n",
    "@njit\n",
    "def sum_numba(S):\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    \n",
    "    suma = 0\n",
    "    for i_s in range(Nx):\n",
    "        suma = suma + sum(S[i_s,:])\n",
    "        \n",
    "    return suma\n",
    "@njit\n",
    "def sum_numba_filas(S): # 2 dimensions\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    suma = np.zeros((Nx))\n",
    "    for i_s in range(Nx):\n",
    "        suma_c = 0 # sum of the column\n",
    "        for i_y in range(Ny):\n",
    "            suma[i_s] = suma_c + S[i_y,i_s] \n",
    "        \n",
    "    return suma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ece41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2,A_f, P_inv_old, i_change, j_change,pp1, pp2): \n",
    "\n",
    "    Nx = L_f_v1v2_old.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0_new , ovlp_1_new = 0,0\n",
    "    ovlp_0_old , ovlp_1_old = 0,0\n",
    "    ovlp_0_dif, ovlp_1_dif = 0,0\n",
    "  \n",
    "    #old and new: changes and mapping changes\n",
    "    changes = np.array([i_change, j_change], dtype = np.int32)\n",
    "    changes_p = np.array([pp1, pp2], dtype = np.int32)  \n",
    "    changes_old = np.array([j_change, i_change], dtype = np.int32)\n",
    "    changes_p_old = np.array([pp2, pp1], dtype = np.int32)\n",
    "    \n",
    "    for i_k in range(K):\n",
    "        for i_chan,change in enumerate(changes):\n",
    "            for i_x in range(Nx):\n",
    "                if (i_k != m1): # Only changes in the networks m1\n",
    "                    p_f = int(P_inv_old[i_k,change])\n",
    "                    p_c = int(P_inv_old[i_k,i_x])\n",
    "                    p_old, p_old_c = p_f, p_c\n",
    "                \n",
    "                else:\n",
    "                    p_f = changes_p[i_chan]\n",
    "                    p_old = changes_p_old[i_chan]\n",
    "                    if (i_x == i_change):\n",
    "                        p_c = pp1\n",
    "                        p_old_c = pp2\n",
    "                    elif(i_x == j_change):\n",
    "                        p_c = pp2\n",
    "                        p_old_c = pp1\n",
    "                    else: # Only changes in the nodes i,j\n",
    "                        p_c = int(P_inv_old[i_k, i_x])\n",
    "                        p_old_c = p_c\n",
    "\n",
    "                ## rows\n",
    "                valor_L_old, valor_A_old = L_f_v1v2_old[i_chan,i_x], A_f[i_k,p_old,p_old_c]   \n",
    "                valor_L_new, valor_A_new = L_f_v1v2[i_chan,i_x], A_f[i_k,p_f,p_c]\n",
    "                ## columns\n",
    "                valor_L_old_c, valor_A_old_c = 0,0\n",
    "                valor_L_new_c, valor_A_new_c = 0,0\n",
    "                column = 0        \n",
    "                if (i_x not in changes):\n",
    "                    column = 1\n",
    "                    valor_L_old_c, valor_A_old_c = L_c_v1v2_old[i_chan,i_x],A_f[i_k,p_old_c, p_old]\n",
    "                    valor_L_new_c, valor_A_new_c = L_c_v1v2[i_chan,i_x], A_f[i_k,p_c,p_f]\n",
    "\n",
    "                ovlp_1_old = ovlp_1_old + valor_L_old*valor_A_old + valor_L_old_c*valor_A_old_c*column\n",
    "                ovlp_0_old = ovlp_0_old + (1-valor_L_old)*(1-valor_A_old) + (1-valor_L_old_c)*(1-valor_A_old_c)*column\n",
    "                \n",
    "                ovlp_1_new = ovlp_1_new + valor_L_new*valor_A_new + valor_L_new_c*valor_A_new_c*column\n",
    "                ovlp_0_new = ovlp_0_new + (1-valor_L_new)*(1-valor_A_new) + (1-valor_L_new_c)*(1-valor_A_new_c)*column\n",
    "                \n",
    "    ovlp_1_def = ovlp_1_new - ovlp_1_old\n",
    "    ovlp_0_def = ovlp_0_new- ovlp_0_old\n",
    "   \n",
    "    return ovlp_0_def, ovlp_1_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7623a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def L_wiring_change_filas(m1,L_old,A_f, i_change, j_change, P_inv_old):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    K = A_f.shape[0] \n",
    "    \n",
    "    L_new_f = L_old.copy()\n",
    "    L_f_v1v2,L_c_v1v2  = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "    \n",
    "    ## changes\n",
    "    changes = np.array([i_change, j_change])\n",
    "    changes_new = np.array([j_change, i_change])\n",
    "    \n",
    "    ## Old values\n",
    "    suma_old =(np.sum(L_old[i_change,:]) + np.sum(L_old[j_change,:]) + np.sum(L_old[:,i_change]) + np.sum(L_old[:,j_change]))-L_old[i_change,j_change]-L_old[j_change,j_change]-L_old[i_change,i_change]-L_old[j_change,i_change]\n",
    "    \n",
    "    ## New row and column\n",
    "    L_new_f[i_change,:], L_new_f[j_change,:], L_new_f[:,i_change], L_new_f[:,j_change] = np.zeros(Nx),np.zeros(Nx),np.zeros(Nx),np.zeros(Nx)\n",
    "    \n",
    "\n",
    "    suma_1 = 0\n",
    "    ## ROWS\n",
    "    for i_i,i_chan in enumerate(changes): #Only looking at the \n",
    "        for i_x in range(Nx):\n",
    "            if (i_x not in changes): # The rest of nodes\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    \n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "\n",
    "            else: # The nodes that change\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                        \n",
    "                        if (i_x == changes_new[0]):\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[1]])\n",
    "                        else:\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[0]])\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                        p2_2 = int(P_inv_old[k,i_x])\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "\n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "                    \n",
    "            valor_lnew_2=1/K*  L_f_v1v2[i_i,i_x]\n",
    "            L_f_v1v2[i_i,i_x] = round( valor_lnew_2 )\n",
    "            \n",
    "                    \n",
    "    ## COLUMNS \n",
    "    for j_j,j_chan in enumerate(changes):\n",
    "        for i_x in range(Nx):\n",
    "            changes_x = 0\n",
    "            if (i_x not in changes):\n",
    "                for k in range(K):\n",
    "                    \n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[j_j]\n",
    "                    else:\n",
    "                        chan_new = changes[j_j]\n",
    "                        \n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    L_c_v1v2[j_j,i_x] += A_f[k,p2_2,p1_2]\n",
    "                \n",
    "                valor_lnew_2=1/K* L_c_v1v2[j_j,i_x]\n",
    "                L_c_v1v2[j_j,i_x] = round( valor_lnew_2)\n",
    "\n",
    "                    \n",
    "            else: # the changes are the same as the columns\n",
    "                changes_x = 1\n",
    "                if (i_x == j_chan):\n",
    "                    L_c_v1v2[j_j,i_x] =  L_f_v1v2[j_j,i_x]\n",
    "                else:\n",
    "                    i_x_inv = changes[j_j]\n",
    "                    if (j_j  == 0):\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[1,i_x_inv]\n",
    "\n",
    "                    else:\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[0,i_x_inv]\n",
    "           \n",
    "    suma_new = np.sum(L_f_v1v2[0,:]) + np.sum(L_f_v1v2[1,:]) + np.sum(L_c_v1v2[0,:]) + np.sum(L_c_v1v2[1,:])-L_c_v1v2[0,j_change]-L_c_v1v2[0,i_change]-L_c_v1v2[1,j_change]-L_c_v1v2[1,i_change]\n",
    "    suma_1 = suma_new - suma_old\n",
    "    return L_f_v1v2,L_c_v1v2, suma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b00922",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def parallel_L_knwn_change(c_parallel,alpha,beta,fijado_f,groups_f, N_groups_f, start_f, end_f,\n",
    "                       A, P_t_f, P_inv_t_f, L_t_f,suma_L, Energy_t_f, ovlp_t_f0, ovlp_t_f1, tempers_f):\n",
    "    \n",
    "    # fijado_f : To let one of the networks fixed or not (If only two networks it doesn't matter)\n",
    "    # c_parallel: counter to change temperatures\n",
    "    # start_f, end,f\n",
    "    # N_groups_f: Number of groups\n",
    "    # groups_f: Directly the ggroup numbeer from the position\n",
    "    \n",
    "    ### Movement:\n",
    "    # 1) Choose one node and see their group (also we can choose a group first)\n",
    "    # 2) Choose another random node inside this group \n",
    "    # 3) Each 4 movements, we propose change the temperatures\n",
    "\n",
    "    N_t = L_t_f.shape[0] # Numbers of tempers\n",
    "    Nx = L_t_f.shape[1] # Numbers of nodes\n",
    "    K = A.shape[0] # Numbers of networks\n",
    "    Edges_sum = K*Nx*Nx\n",
    "   \n",
    "    if (c_parallel <4*Nx): # If not change of temperatures\n",
    "        c_parallel += 1\n",
    "        \n",
    "        #Choose the networks to propose the change (in all temperatures)\n",
    "        if (fijado_f == 1):\n",
    "            m1 = np.random.randint(K-1)+1 #One networks\n",
    "        else:\n",
    "            m1 = np.random.randint(K)    \n",
    "        \n",
    "        for k_nt in range(N_t):            \n",
    "            # 1) Choose a random node (node in A)\n",
    "            v1_mapping = np.random.randint(start_f[0], Nx)\n",
    "            # Inside the group:\n",
    "            grupo = groups_f[k_nt,m1,v1_mapping]\n",
    "            start, end = start_f[grupo], end_f[grupo]\n",
    "            size_group = end - start\n",
    "            todos = size_group \n",
    "            if (size_group > 1): \n",
    "\n",
    "                v2_mapping = np.random.randint(start, end)\n",
    "                while (v2_mapping == v1_mapping):\n",
    "                    v2_mapping = np.random.randint(start, end)\n",
    "\n",
    "                # Nodes in L\n",
    "                v1 = P_t_f[k_nt, m1,v1_mapping]\n",
    "                v2 = P_t_f[k_nt, m1, v2_mapping]\n",
    "\n",
    "\n",
    "                ### Only changes in the specific columns and rows\n",
    "                L_f_v1v2, L_f_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "                L_c_v1v2, L_c_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "\n",
    "                pp_1 = int(P_inv_t_f[k_nt,m1,v2]) # v2_mapping\n",
    "                pp_2 = int(P_inv_t_f[k_nt,m1,v1]) # v1_mapping\n",
    "                \n",
    "                # Changes in the blueprint\n",
    "                L_f_v1v2,L_c_v1v2 , suma_aux = L_wiring_change_filas(m1,L_t_f[k_nt,:,:], A, v1, v2, P_inv_t_f[k_nt,:,:])\n",
    "                L_f_v1v2_old[0,:],L_f_v1v2_old[1,:] = L_t_f[k_nt,v1,:].copy(),L_t_f[k_nt,v2,:].copy()\n",
    "                L_c_v1v2_old[0,:],L_c_v1v2_old[1,:] = L_t_f[k_nt,:,v1].copy(),L_t_f[k_nt,:,v2].copy()\n",
    "                \n",
    "                # Parameters to change\n",
    "                Edges_L = K*(suma_L[k_nt] + suma_aux)\n",
    "                Edges_NoL = Edges_sum - Edges_L\n",
    "                ovl_0_new, ovl_1_new = overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2 ,A,P_inv_t_f[k_nt,:,:], v1,v2, pp_1, pp_2)\n",
    "                overlap_0,overlap_1 = ovlp_t_f0[k_nt] + ovl_0_new, ovlp_t_f1[k_nt] + ovl_1_new\n",
    "                Energy_bucle = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "                dE_sampler = Energy_bucle - Energy_t_f[k_nt]\n",
    "                dE_t = dE_sampler\n",
    "\n",
    "\n",
    "                ### UPDATE\n",
    "                if (dE_t < 0):\n",
    "                    \n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:].copy(),L_f_v1v2[1,:].copy()\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:].copy(),L_c_v1v2[1,:].copy()\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "                elif (np.random.rand() < np.exp(-dE_t*tempers_f[k_nt])):\n",
    "\n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:].copy(),L_f_v1v2[1,:].copy()\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:].copy(),L_c_v1v2[1,:].copy()\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "    else: # Change in temperatures\n",
    "        c_parallel = 0 \n",
    "        \n",
    "        mt1 = np.random.randint(N_t)  #temper 1\n",
    "        mt2 =  np.random.randint(N_t) #temper 2\n",
    "        while (mt1 == mt2):\n",
    "            mt2 = np.random.randint(N_t)\n",
    "\n",
    "        Energy_1 = Energy_t_f[mt1]\n",
    "        Energy_2 = Energy_t_f[mt2] \n",
    "\n",
    "        dE_parallel = -(tempers_f[mt1]-tempers_f[mt2])*(Energy_1-Energy_2)\n",
    "        if (dE_parallel <0):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            # 1 --> 2\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "\n",
    "            # 2 --> 1\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "        elif (np.random.rand() < np.exp(-dE_parallel)):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            # 1 --> 2\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "\n",
    "            # 2 --> 1\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "    return c_parallel, P_t_f, P_inv_t_f,Energy_t_f, ovlp_t_f0, ovlp_t_f1, L_t_f, suma_L, groups_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bc917",
   "metadata": {},
   "source": [
    "# Running MonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078591b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fijado = 0 # To maintain fix the first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6af79cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy with the reference mapping: 7755.326264092393\n",
      "overlap_0: 190738 /overlap_1: 8687\n",
      "%Overlaps: 99.36274314413265 %\n"
     ]
    }
   ],
   "source": [
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i]=i \n",
    "        P_inv_new[k,i]=i            \n",
    "L_new = np.zeros((Nx,Nx)) \n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) # Los edges=1 que tiene la matriz A\n",
    "Edges_NoL = Edges_sum - Edges_L #Los edges=0 que tiene la matriz A\n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "print('Energy with the reference mapping:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9804fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy with the reference mapping: 7755.326264092393\n",
      "overlap_0: 190738 /overlap_1: 8687\n",
      "%Overlaps: 99.36274314413265 %\n",
      "\n",
      "Initial energy with L = A[0]: 67.16518055187771\n",
      "\n",
      "Energy with L_wiring: 37880.12383809883\n",
      "overlaps 0: 190546 1: 723\n",
      "%Overlaps: 95.29904735331633 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|████████████████████▉                 | 5500/10000 [19:45<17:00,  4.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5500 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████████████████████▊               | 6000/10000 [21:35<14:15,  4.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6000 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|████████████████████████▋             | 6500/10000 [23:24<12:13,  4.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6500 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████▌           | 7000/10000 [25:13<11:04,  4.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7000 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|████████████████████████████▌         | 7500/10000 [26:58<08:48,  4.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7500 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████▍       | 8000/10000 [28:47<07:07,  4.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8000 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████████████████████████████▎     | 8500/10000 [30:37<05:26,  4.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8500 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████▏   | 9000/10000 [32:25<03:40,  4.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9000 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|████████████████████████████████████  | 9500/10000 [34:16<01:49,  4.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9500 Energy (temper = 1): 7755.326264092393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 10000/10000 [36:06<00:00,  4.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (after compilation) = 2166.6348910331726\n",
      "Energy final: [7755.32626409 7755.32626409 7755.32626409 7755.32626409 7755.32626409\n",
      " 7755.32626409 7755.32626409 7755.32626409 7755.32626409 7755.32626409\n",
      " 7755.32626409 7755.32626409 7755.32626409 7755.32626409 7755.32626409] /Computed final: [7755.32626409 7755.32626409 7755.32626409 7755.32626409 7755.32626409\n",
      " 7755.32626409 7755.32626409 7755.32626409 7755.32626409 7755.32626409\n",
      " 7755.32626409 7755.32626409 7755.32626409 7755.32626409 7755.32626409]\n",
      "overlaps_0: 190738 overlap_1: 8687 %overlaps: 99.36274314413265 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed( random.randint(1,1999))\n",
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i]=i \n",
    "        P_inv_new[k,i]=i            \n",
    "L_new = np.zeros((Nx,Nx))\n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) # edges=1 in A\n",
    "Edges_NoL = Edges_sum - Edges_L # edges=0 in A\n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "print('Energy with the reference mapping:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n",
    "\n",
    "\n",
    "# VARIABLE USING INITIAL CONDITIONS\n",
    "P_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_t = np.zeros((N_t,K,Nx))\n",
    "L_t = np.zeros((N_t,Nx, Nx))\n",
    "Energy_t, Energy_ini_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "Edges_L_t, Edges_NoL_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "groups_t = np.zeros((N_t, K, Nx))\n",
    "ovlp_ini0_t = np.zeros((N_t)) + ovlp_ini0\n",
    "ovlp_ini1_t = np.zeros((N_t)) + ovlp_ini1\n",
    "ovlp_ini0_t, ovlp_ini1_t = ovlp_ini0_t.astype(int), ovlp_ini1_t.astype(int)\n",
    "ovlp_t0, ovlp_t1 = np.zeros((N_t)) + ovlp_ini0, np.zeros((N_t)) + ovlp_ini1\n",
    "P_t = (P_ini_t).copy()\n",
    "P_inv_t = (P_inv_ini_t).copy()\n",
    "L_t = (L_ini_t).copy()\n",
    "groups_t = groups_ini_t.copy()\n",
    "#Integer variables\n",
    "ovlp_t0, ovlp_t1 = ovlp_t0.astype(int), ovlp_t1.astype(int)\n",
    "P_t = P_t.astype(int)\n",
    "P_inv_t = P_inv_t.astype(int)\n",
    "L_t = L_t.astype(int)\n",
    "groups_t = groups_t.astype(int)\n",
    "\n",
    "## Initial energy with L = A[0]\n",
    "Edges_L = K*sum(sum(L_ini))\n",
    "Edges_NoL = Edges_sum - Edges_L            \n",
    "Energy_ini = hamiltonian_prob(Edges_NoL, Edges_L, ovlp_ini0, ovlp_ini1 ,alpha, beta)\n",
    "Energy_ini_t = np.zeros((N_t))+ Energy_ini \n",
    "print()\n",
    "print('Initial energy with L = A[0]:', Energy_ini)\n",
    "print()\n",
    "\n",
    "\n",
    "#### Now the Blueprint is averaged\n",
    "for k_nt in range(N_t):\n",
    "    L_t[k_nt,:,:] =  L_wiring(A, P_inv_t[k_nt,:,:])\n",
    "    Edges_L_t[k_nt] = K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL_t[k_nt] = Edges_sum - Edges_L_t[k_nt]\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_t[k_nt] = hamiltonian_prob(Edges_NoL_t[k_nt], Edges_L_t[k_nt], overlap_0, overlap_1,alpha, beta)\n",
    "    ovlp_t0[k_nt], ovlp_t1[k_nt] = overlap_0, overlap_1\n",
    "print('Energy with L_wiring:', Energy_t[0]) \n",
    "print('overlaps 0:', ovlp_t0[0], '1:', ovlp_t1[0])\n",
    "print('%Overlaps:',100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n",
    "Energy_ini_wiring = Energy_t.copy()\n",
    "suma_L_t = np.zeros(N_t)\n",
    "for k_nt in range(N_t):\n",
    "    suma_L_t[k_nt] = sum_numba(L_t[k_nt,:,:])\n",
    "\n",
    "\n",
    "### MONTE CARLO\n",
    "# Parameters\n",
    "PasosMC = 10000\n",
    "Long_corr = 500\n",
    "Pasos_corr = 5000\n",
    "Pasos_store = int((PasosMC - Pasos_corr)/Long_corr)\n",
    "if (Pasos_store<0):\n",
    "    Pasos_store = 0\n",
    "steps_middle_0 = 500\n",
    "steps_middle_1 = 1000\n",
    "    \n",
    "# Variables to store    \n",
    "energies_pasos = np.zeros((N_t,PasosMC))\n",
    "energies_pasos[:,0] = Energy_ini_wiring\n",
    "count_parallel, count_unl = 0, 0\n",
    "P_store = np.zeros((Pasos_store,N_t, K, Nx))\n",
    "groups_store = np.zeros((Pasos_store, N_t,K,Nx))\n",
    "Energy_store = np.zeros((Pasos_store, N_t))\n",
    "L_store = np.zeros((Pasos_store,N_t, Nx, Nx))\n",
    "P_intermediate_shot = np.zeros((2,N_t,K,Nx))\n",
    "E_intermediate_shot = np.zeros((2,N_t))\n",
    "\n",
    "\n",
    "#######################################\n",
    "start = time.time()\n",
    "count_parallel, count_long, i_long = 0,0,0\n",
    "for i_mc in tqdm(range(0,PasosMC)):\n",
    "    ## Starting to store sampling configurations\n",
    "    if (i_mc > Pasos_corr):\n",
    "        count_long += 1\n",
    "        if (count_long == Long_corr):\n",
    "            count_long = 0\n",
    "            P_store[i_long,:,:,:] = P_t.copy()\n",
    "            Energy_store[i_long,:] = Energy_t.copy()\n",
    "            L_store[i_long,:,:,:] = L_t.copy()\n",
    "            groups_store[i_long, :,:] = groups_t.copy()\n",
    "            i_long += 1\n",
    "            print('Step', i_mc, 'Energy (temper = 1):', Energy_t[4])\n",
    "    \n",
    "    ## Store transient configurations\n",
    "    if (i_mc == steps_middle_0 ):\n",
    "        P_intermediate_shot[0,:,:,:] = P_t.copy()\n",
    "        E_intermediate_shot[0,:] = Energy_t.copy()\n",
    "    if (i_mc == steps_middle_1 ):\n",
    "        P_intermediate_shot[1,:,:,:] = P_t.copy()\n",
    "        E_intermediate_shot[1,:] = Energy_t.copy()\n",
    "\n",
    "\n",
    "    energies_pasos[:, i_mc] = Energy_t[:]\n",
    "    for i_micro in range(Nx):\n",
    "\n",
    "        count_parallel,P_t, P_inv_t, Energy_t, ovlp_t0, ovlp_t1, L_t,suma_L_t, groups_t = parallel_L_knwn_change( count_parallel,alpha,beta,fijado,groups_t,n_groups, start_groups, \n",
    "                                                                                                 end_groups, A, P_t, P_inv_t, L_t,suma_L_t, Energy_t, ovlp_t0, \n",
    "                                                                                                 ovlp_t1, tempers)\n",
    "\n",
    "                                                                                                  \n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))  \n",
    "\n",
    "## Final energy\n",
    "Energy_calculada = np.zeros((N_t))\n",
    "for k_nt in range(N_t):\n",
    "    Edges_L= K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL = Edges_sum - Edges_L\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_calculada[k_nt] = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "    \n",
    "print('Energy final:', Energy_t, '/Computed final:', Energy_calculada) \n",
    "print('overlaps_0:', ovlp_t0[0], 'overlap_1:', ovlp_t1[0], '%overlaps:', 100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96685938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a construir un diccionario para guardar todo\n",
    "d_store={}\n",
    "string = \"prueba.pickle\"\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"Permus_inv\"] = P_inv_t\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "\n",
    "d_store[\"P_inter\"] = P_intermediate_shot\n",
    "d_store[\"E_inter\"] = E_intermediate_shot\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "d_store[\"L_store\"] = L_store\n",
    "\n",
    "d_store[\"E_groundtruth\"] = Energy_new\n",
    "d_store[\"Pasos_corr_ini\"] = Pasos_corr \n",
    "d_store[\"Step_corr\"] = Long_corr \n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "# prueba = pickle.load(open(string, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3fdfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a construir un diccionario para guardar todo\n",
    "d_store={}\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"Permus_inv\"] = P_inv_t\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "\n",
    "\n",
    "\n",
    "d_store[\"P_inter\"] = P_intermediate_shot\n",
    "d_store[\"E_inter\"] = E_intermediate_shot\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "d_store[\"L_store\"] = L_store\n",
    "\n",
    "d_store[\"E_groundtruth\"] = Energy_new\n",
    "d_store[\"Pasos_corr_ini\"] = Pasos_corr \n",
    "d_store[\"Step_corr\"] = Long_corr \n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "prueba = pickle.load(open(string, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "be925fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tempers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b6c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
