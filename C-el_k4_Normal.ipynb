{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69eba05",
   "metadata": {},
   "source": [
    "# Parallel Tempering\n",
    "\n",
    "In the following code, we will use data from https://www.nature.com/articles/s41586-021-03778-8\n",
    "\n",
    "In this case, we will align the last four connectome networks, corresponding to the latest stages of development: L2,L3, A1, A2\n",
    "\n",
    "In this notebook we are not working with weighted networks, only with the presence or not of a connection (Binary adjacency matrices).\n",
    "\n",
    "Blablabla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eefb8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numba import jit, njit\n",
    "from numba.types import bool_, int_, float32\n",
    "from math import comb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a0ae0a",
   "metadata": {},
   "source": [
    "# DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c848c94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichero leído: 0 tamaño (227, 183)\n",
      "Fichero leído: 1 tamaño (227, 183)\n",
      "Fichero leído: 2 tamaño (227, 183)\n",
      "Fichero leído: 3 tamaño (227, 183)\n",
      "Fichero leído: 4 tamaño (227, 183)\n",
      "Fichero leído: 5 tamaño (227, 183)\n",
      "Fichero leído: 6 tamaño (227, 183)\n",
      "Fichero leído: 7 tamaño (227, 183)\n"
     ]
    }
   ],
   "source": [
    "### Open the files\n",
    "tablas = 8\n",
    "n_grupo = 4\n",
    "\n",
    "d = {}\n",
    "D = \"Dataset\"\n",
    "for i in range(0,tablas):\n",
    "    d[\"group\" + str(i)] = pd.read_excel(\"datasets.ods\", sheet_name=D+str(i+1))\n",
    "    print('Read:',i, 'size', d[\"group\" + str(i)].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cae59472",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hipermatrix M with the data (Only the synapses) \n",
    "rows = d[\"group\" + str(i)].shape[0] - 3\n",
    "columns = d[\"group\" + str(i)].shape[1] - 3\n",
    "\n",
    "M = np.zeros((tablas,rows,columns))\n",
    "for i in range(0, tablas):\n",
    "    Data = d['group' + str(i)]\n",
    "    M[i,:,:] = Data.iloc[3:,3:]\n",
    "    \n",
    "## Since we work with same number of nodes, we want them equal and square (zeros when no connections)\n",
    "M_square = np.zeros((tablas, rows, rows))\n",
    "M_square[:,:, 0:columns] = M[:,:,:]\n",
    "\n",
    "## Binarization: No weights\n",
    "#Lo queremos BINARIO, ignorando su peso (Luego pensar cómo se haría con el peso)\n",
    "M_square_bin = np.zeros((tablas,rows,rows))\n",
    "for i in range(tablas):\n",
    "    for j in range(rows):\n",
    "        for k in range(columns):\n",
    "            if (M[i,j,k] >= 1):\n",
    "                M_square_bin[i,j,k] = 1\n",
    "                \n",
    "Nx = rows # Number of nodes (we imposed rows == columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cb1e46",
   "metadata": {},
   "source": [
    "### GROUP INFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c5e011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grupos: Sensory, Inter, Motor, Modulatory, Muscle, Other\n",
      "SIZE GROUPS: [65 44 42 29 32 12]\n",
      "***********************************\n",
      "First node in each group [  0  65 109 151 180 212]\n",
      "Last node in each group [ 65 109 151 180 212 224]\n"
     ]
    }
   ],
   "source": [
    "# Groups from the database\n",
    "Sensory = 69-5 #0\n",
    "Inter = 113-70 # 1\n",
    "Motor = 155-114 #2\n",
    "Modulatory = 184-156 #3\n",
    "Muscle = 216-185 #4 \n",
    "Others = 228-217 #5\n",
    "\n",
    "size_groups = np.array([Sensory, Inter, Motor, Modulatory, Muscle, Others]) + 1 #Started in 0\n",
    "n_groups = len(size_groups)\n",
    "start_groups = np.zeros(n_groups)\n",
    "end_groups = np.zeros(n_groups)\n",
    "\n",
    "\n",
    "print('grupos: Sensory, Inter, Motor, Modulatory, Muscle, Other')\n",
    "print('SIZE GROUPS:', size_groups)\n",
    "\n",
    "\n",
    "#Para evitar trabajar con diccionarios (por NUMBA), vamos a hacer matrices \n",
    "# Cada matriz tiene el tamaño de la de mayor, pero luego las vamos cortando\n",
    "rows_g, columns_g = size_groups.max(), size_groups.max()\n",
    "\n",
    "size_suma = 0\n",
    "start_groups[0] = 0\n",
    "for i in range(n_groups):\n",
    "    size = size_groups[i]\n",
    "    if (i != n_groups-1):\n",
    "        start_groups[i+1] = int(size_suma + size)\n",
    "    size_suma = size_suma + (size) \n",
    "#end\n",
    "for i in range(0,n_groups):\n",
    "    if (i!= n_groups-1):\n",
    "        end_groups[i] = start_groups[i+1]\n",
    "    else:\n",
    "        end_groups[i] = Nx\n",
    "start_groups = start_groups.astype(int)\n",
    "end_groups = end_groups.astype(int)\n",
    "\n",
    "print('***********************************')\n",
    "print('First node in each group', start_groups)\n",
    "print('Last node in each group', end_groups)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955c46f",
   "metadata": {},
   "source": [
    "## ENERGY FUNCTIONS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90620ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta):\n",
    "\n",
    "    A_1 = overlap_1 + alpha\n",
    "    B_1 = (Edges_L - overlap_1 + beta)\n",
    "    C_1 = Edges_L + alpha + beta\n",
    "    \n",
    "    A_0 = overlap_0 + alpha\n",
    "    B_0 = (Edges_NoL - overlap_0 + beta)\n",
    "    C_0 = Edges_NoL + alpha + beta\n",
    "    \n",
    "    #  [ math.lgamma(n+1) == log(n!) ]\n",
    "    H1 = math.lgamma(A_1)+ math.lgamma(B_1) - math.lgamma(C_1) \n",
    "    H0 = math.lgamma(A_0)+ math.lgamma(B_0) - math.lgamma(C_0) \n",
    "    \n",
    "    H = -(H1 + H0)\n",
    "    return H\n",
    "    \n",
    "    \n",
    "@jit(nopython=True)\n",
    "def overlap_total_prob(L_f, A_f, P_inv_f):\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0 = np.zeros((K))\n",
    "    ovlp_1 = np.zeros((K))\n",
    "    for k in range(0,K):\n",
    "        for f in range(0,Ny): \n",
    "            for c in range(0,Nx):\n",
    "                p_f=int(P_inv_f[k,f])\n",
    "                p_c=int(P_inv_f[k,c])  \n",
    "                \n",
    "                valor_L, valor_A = L_f[f,c], A_f[k,p_f,p_c]\n",
    "                \n",
    "                ovlp_0[k] = ovlp_0[k] + (1-valor_L)*(1-valor_A )\n",
    "                ovlp_1[k] = ovlp_1[k] + valor_L*valor_A\n",
    "                \n",
    "                \n",
    "    ovlp_1 = int(sum(ovlp_1))\n",
    "    ovlp_0 = int(sum(ovlp_0))\n",
    "    return ovlp_0, ovlp_1\n",
    "\n",
    "\n",
    "@jit(nopython=True) # The blueprint is the average of the observations (taking into account the mapping)  \n",
    "def L_wiring(A_f, P_inv_f):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "    L_new_f = np.zeros((Nx,Ny))\n",
    "    \n",
    "    for i in range(0,Nx):\n",
    "        for j in range(0,Ny):\n",
    "            for k in range(0,K):\n",
    "        \n",
    "                p1 = int(P_inv_f[k,i]) # Mapping of the observations\n",
    "                p2 = int(P_inv_f[k,j]) # Mapping of the observations\n",
    "                L_new_f[i,j] += A_f[k,p1,p2]\n",
    "            valor_lnew=1/K* L_new_f[i,j]\n",
    "            L_new_f[i,j] = round( valor_lnew ) \n",
    "            # If valor_lnew = 0, L=0 (we could establish L=1, but it is more probable to not have a connection)\n",
    "    \n",
    "    return L_new_f\n",
    "\n",
    "\n",
    "#### Some algorithm for sorting\n",
    "@jit(nopython=True)\n",
    "def partition(array,  etiquetas, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if array[i] < array[begin]:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "            etiquetas[i], etiquetas[pivot] = etiquetas[pivot], etiquetas[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    etiquetas[pivot], etiquetas[begin] = etiquetas[begin], etiquetas[pivot] \n",
    "\n",
    "    return pivot\n",
    "@jit(nopython=True)\n",
    "def quicksort(array, etiquetas, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    if begin >= end: #To end\n",
    "        return\n",
    "    pivot = partition(array,  etiquetas, begin, end)\n",
    "    \n",
    "    #Order right and left\n",
    "    quicksort(array, etiquetas, begin, pivot-1)\n",
    "    quicksort(array,  etiquetas, pivot+1, end)\n",
    "    \n",
    "@njit \n",
    "# We inizialise the algorithm sorting by node degree, but also taking into account the group labels\n",
    "def permu_groups(L_f, A_f, start_f): \n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    N_groups = len(start_f)\n",
    "    \n",
    "    \n",
    "    # Mappings\n",
    "    P_f = np.zeros((K,Nx)) #Mapping from L to A\n",
    "    P_inv_f = np.zeros((K,Nx)) #Mapping from A to L\n",
    "    P_new = np.zeros((K,Nx))\n",
    "    \n",
    "    # First we order the blueprint and after the observations\n",
    "    # Blueprint:\n",
    "    orden_L=np.zeros((Nx))\n",
    "    for i in range(Nx):\n",
    "        b=np.nonzero(L_f[i,:])\n",
    "        orden_L[i] = b[0].size\n",
    "        \n",
    "    array_L = np.arange(Nx) #For the labels \n",
    "    quicksort(orden_L, array_L)\n",
    "    \n",
    "    # Now according to the group label\n",
    "    array_L_labels = np.zeros((Nx))\n",
    "    group_number = np.zeros((N_groups))\n",
    "    for i in range(Nx):\n",
    "        n_type = 0\n",
    "        #Group\n",
    "        while ( (array_L[i] >= start_f[n_type]) and (n_type < N_groups)):\n",
    "            n_type += 1\n",
    "       \n",
    "        grupo = int(n_type-1)\n",
    "        g = int(start_f[grupo])\n",
    "        array_L_labels[g + int(group_number[grupo])] = array_L[i]\n",
    "        group_number[grupo] += 1\n",
    "\n",
    "    #Observations: \n",
    "    for i in range(0,K):\n",
    "        orden_A = np.zeros((Nx))\n",
    "        for i_orden in range(Nx):\n",
    "            b = np.nonzero(A_f[i,i_orden,:])\n",
    "            orden_A[i_orden] = b[0].size\n",
    "\n",
    "        array_A = np.arange(Nx) #For the labels \n",
    "        quicksort(orden_A, array_A)\n",
    "            \n",
    "        # Now according to the group label\n",
    "        array_A_labels = np.zeros((Nx))\n",
    "        group_number = np.zeros((N_groups))\n",
    "        \n",
    "        for i_g in range(Nx):\n",
    "            n_type = 0\n",
    "            while ( (array_A[i_g] >= start_f[n_type]) and (n_type < N_groups) ):\n",
    "                n_type += 1\n",
    "\n",
    "            grupo = int(n_type-1)\n",
    "            g = int(start_f[grupo])\n",
    "            array_A_labels[ g + int(group_number[grupo])] = array_A[i_g]\n",
    "            group_number[grupo] += 1\n",
    "    \n",
    "\n",
    "    # Now ordered together both label array  array_L = [0,1,2,3...]\n",
    "        array_A_labels = array_A_labels[np.argsort(array_L_labels)]\n",
    "        P_f[i,:] = array_A_labels\n",
    "        \n",
    "        for i_inv in range(0,Nx):\n",
    "            for j_inv in range(0,Ny):\n",
    "                if (P_f[i,i_inv] == j_inv):\n",
    "                    P_inv_f[i, j_inv]=i_inv\n",
    "    \n",
    "    P_todo = np.zeros((2,K,Nx))\n",
    "    P_todo[0,:,:] = P_f.copy() \n",
    "    P_todo[1,:,:] = P_inv_f.copy()\n",
    "\n",
    "    return P_todo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2881b5b",
   "metadata": {},
   "source": [
    "## INITIAL CONDITIONS\n",
    "\n",
    "We will align the 4 last networks: L2, L3, A1, A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32ce360e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OBSERVATIONS\n",
      "(4, 224, 224)\n",
      "*************************\n",
      "[[ 0  1  2  3  4  5  6  7  8  9]\n",
      " [ 4 46 55 41 44 53 23 35  8 49]\n",
      " [15  2 39 35 46 28 31 63 20 36]\n",
      " [39 15 64 58  7 54 26 40 38 37]]\n"
     ]
    }
   ],
   "source": [
    "Nx = rows # Nodes\n",
    "K = 4 # Number of networks\n",
    "alpha,beta = 5,2 # Values for the beta prior distribution \n",
    "Edges = Nx*Nx \n",
    "micropasos = Edges*K #Microsteps for each MCMC\n",
    "A = np.zeros((K,Nx,Nx))\n",
    "A = M_square_bin[4:, :,:] #Only the latest four                \n",
    "print('OBSERVATIONS')  \n",
    "print(A.shape)\n",
    "####################################\n",
    "\n",
    "## INITIALIZATION ##\n",
    "\n",
    "L_ini = np.zeros((Nx,Nx))\n",
    "P_ini_0 = np.zeros((K,Nx))\n",
    "P_inv_ini_0 = np.zeros((K,Nx))\n",
    "\n",
    "# We inizialize with the Blueprint = L2\n",
    "L_ini = (A[0,:,:]).copy()\n",
    "\n",
    "groups_ini = np.zeros((K,Nx)) #Groups label\n",
    "for m1 in range(K):\n",
    "    for i_g in range(n_groups):\n",
    "        start = start_groups[i_g]\n",
    "        end = end_groups[i_g]\n",
    "        groups_ini[m1, start:end] = i_g\n",
    "        \n",
    "## Overlaps\n",
    "ovlp_ini0, ovlp_ini1 = overlap_total_prob(L_ini,A,P_inv_ini_0)\n",
    "\n",
    "        \n",
    "# Inizialization according to node-degree (taking into account group labels)\n",
    "P_inis = permu_groups(L_ini, A, start_groups)\n",
    "P_inis = P_inis.astype(int)\n",
    "P_ini_0 = (P_inis[0,:,:]).copy() # Mapping L to A\n",
    "P_inv_ini_0 = (P_inis[1,:,:]).copy() # Mapping A to L\n",
    "print('*************************')\n",
    "print(P_ini_0[:,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea5703",
   "metadata": {},
   "source": [
    "## Temperatures\n",
    "\n",
    "We are permorfing a Parallel tempering Markov Chain MonteCarlo\n",
    "\n",
    "We run our MCMC at difference temperatures (proposing changes between them), and we will sample at temper = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c07022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas: [0.86260878 0.88101504 0.89981405 0.91901419 0.93862401 0.95865228\n",
      " 0.9791079  1.         1.0213379  1.0431311  1.06538932 1.08812249\n",
      " 1.11134073 1.1350544  1.15927407]\n"
     ]
    }
   ],
   "source": [
    "# Temperature distributin\n",
    "beta_o = 1.03\n",
    "total = 15 # Odd name, in order to have beta = 1\n",
    "b_exp = np.linspace(-5,5,num = total)\n",
    "tempers = beta_o**b_exp # Account for 1/KT, called beta in thermodinamics\n",
    "print('betas:', tempers)\n",
    "N_t = len(tempers)\n",
    "\n",
    "## Inizialitation of the system for each temperature, with the same mappings\n",
    "P_ini_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_ini_t = np.zeros((N_t,K,Nx))\n",
    "L_ini_t = np.zeros((N_t,Nx,Nx)) \n",
    "groups_ini_t = np.zeros((N_t, K, Nx ))\n",
    "\n",
    "for i in range(0,N_t): \n",
    "    P_ini_t[i,:,:] = P_ini_0[:,:].copy()\n",
    "    P_inv_ini_t[i,:,:] = P_inv_ini_0[:,:].copy()\n",
    "    L_ini_t[i,:,:] = L_ini.copy()\n",
    "    groups_ini_t[i,:,:] = groups_ini.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060faab1",
   "metadata": {},
   "source": [
    "# MONTE CARLO FUNCTIONS \n",
    "\n",
    "Probably some functions are easy to optimize.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84568c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Some functions that numba do not have\n",
    "@njit\n",
    "def concatenate_numba_sinrep(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    no_double = []\n",
    "    for i_b in range(size_b):\n",
    "        if b[i_b] in a:\n",
    "            size_b = size_b-1\n",
    "        else:\n",
    "            no_double.append(b[i_b])\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = no_double\n",
    "    \n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def concatenate_numba(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = b \n",
    "    \n",
    "    return c\n",
    "\n",
    "@njit\n",
    "def sum_numba(S):\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    \n",
    "    suma = 0\n",
    "    for i_s in range(Nx):\n",
    "        suma = suma + sum(S[i_s,:])\n",
    "        \n",
    "    return suma\n",
    "@njit\n",
    "def sum_numba_filas(S): # 2 dimensions\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    suma = np.zeros((Nx))\n",
    "    for i_s in range(Nx):\n",
    "        suma_c = 0 # sum of the column\n",
    "        for i_y in range(Ny):\n",
    "            suma[i_s] = suma_c + S[i_y,i_s] \n",
    "        \n",
    "    return suma\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ece41d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2,A_f, P_inv_old, i_change, j_change,pp1, pp2): \n",
    "\n",
    "    Nx = L_f_v1v2_old.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0_new , ovlp_1_new = 0,0\n",
    "    ovlp_0_old , ovlp_1_old = 0,0\n",
    "    ovlp_0_dif, ovlp_1_dif = 0,0\n",
    "  \n",
    "    #old and new: changes and mapping changes\n",
    "    changes = np.array([i_change, j_change], dtype = np.int32)\n",
    "    changes_p = np.array([pp1, pp2], dtype = np.int32)  \n",
    "    changes_old = np.array([j_change, i_change], dtype = np.int32)\n",
    "    changes_p_old = np.array([pp2, pp1], dtype = np.int32)\n",
    "    \n",
    "    for i_k in range(K):\n",
    "        for i_chan,change in enumerate(changes):\n",
    "            for i_x in range(Nx):\n",
    "                if (i_k != m1): # Only changes in the networks m1\n",
    "                    p_f = int(P_inv_old[i_k,change])\n",
    "                    p_c = int(P_inv_old[i_k,i_x])\n",
    "                    p_old, p_old_c = p_f, p_c\n",
    "                \n",
    "                else:\n",
    "                    p_f = changes_p[i_chan]\n",
    "                    p_old = changes_p_old[i_chan]\n",
    "                    if (i_x == i_change):\n",
    "                        p_c = pp1\n",
    "                        p_old_c = pp2\n",
    "                    elif(i_x == j_change):\n",
    "                        p_c = pp2\n",
    "                        p_old_c = pp1\n",
    "                    else: # Only changes in the nodes i,j\n",
    "                        p_c = int(P_inv_old[i_k, i_x])\n",
    "                        p_old_c = p_c\n",
    "\n",
    "                ## rows\n",
    "                valor_L_old, valor_A_old = L_f_v1v2_old[i_chan,i_x], A_f[i_k,p_old,p_old_c]   \n",
    "                valor_L_new, valor_A_new = L_f_v1v2[i_chan,i_x], A_f[i_k,p_f,p_c]\n",
    "                ## columns\n",
    "                valor_L_old_c, valor_A_old_c = 0,0\n",
    "                valor_L_new_c, valor_A_new_c = 0,0\n",
    "                column = 0                if (i_x not in changes):\n",
    "                    column = 1\n",
    "                    valor_L_old_c, valor_A_old_c = L_c_v1v2_old[i_chan,i_x],A_f[i_k,p_old_c, p_old]\n",
    "                    valor_L_new_c, valor_A_new_c = L_c_v1v2[i_chan,i_x], A_f[i_k,p_c,p_f]\n",
    "\n",
    "                ovlp_1_old = ovlp_1_old + valor_L_old*valor_A_old + valor_L_old_c*valor_A_old_c*column\n",
    "                ovlp_0_old = ovlp_0_old + (1-valor_L_old)*(1-valor_A_old) + (1-valor_L_old_c)*(1-valor_A_old_c)*column\n",
    "                \n",
    "                ovlp_1_new = ovlp_1_new + valor_L_new*valor_A_new + valor_L_new_c*valor_A_new_c*column\n",
    "                ovlp_0_new = ovlp_0_new + (1-valor_L_new)*(1-valor_A_new) + (1-valor_L_new_c)*(1-valor_A_new_c)*column\n",
    "                \n",
    "    ovlp_1_def = ovlp_1_new - ovlp_1_old\n",
    "    ovlp_0_def = ovlp_0_new- ovlp_0_old\n",
    "   \n",
    "    return ovlp_0_def, ovlp_1_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7623a272",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def L_wiring_change_filas(m1,L_old,A_f, i_change, j_change, P_inv_old):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    K = A_f.shape[0] \n",
    "    \n",
    "    L_new_f = L_old.copy()\n",
    "    L_f_v1v2,L_c_v1v2  = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "    \n",
    "    ## changes\n",
    "    changes = np.array([i_change, j_change])\n",
    "    changes_new = np.array([j_change, i_change])\n",
    "    \n",
    "    ## Old values\n",
    "    suma_old =(np.sum(L_old[i_change,:]) + np.sum(L_old[j_change,:]) + np.sum(L_old[:,i_change]) + np.sum(L_old[:,j_change]))-L_old[i_change,j_change]-L_old[j_change,j_change]-L_old[i_change,i_change]-L_old[j_change,i_change]\n",
    "    \n",
    "    ## New row and column\n",
    "    L_new_f[i_change,:], L_new_f[j_change,:], L_new_f[:,i_change], L_new_f[:,j_change] = np.zeros(Nx),np.zeros(Nx),np.zeros(Nx),np.zeros(Nx)\n",
    "    \n",
    "\n",
    "    suma_1 = 0\n",
    "    ## ROWS\n",
    "    for i_i,i_chan in enumerate(changes): #Only looking at the \n",
    "        for i_x in range(Nx):\n",
    "            if (i_x not in changes): # The rest of nodes\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    \n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "\n",
    "            else: # The nodes that change\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                        \n",
    "                        if (i_x == changes_new[0]):\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[1]])\n",
    "                        else:\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[0]])\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                        p2_2 = int(P_inv_old[k,i_x])\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "\n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "                    \n",
    "            valor_lnew_2=1/K*  L_f_v1v2[i_i,i_x]\n",
    "            L_f_v1v2[i_i,i_x] = round( valor_lnew_2 )\n",
    "            \n",
    "                    \n",
    "    ## COLUMNS \n",
    "    for j_j,j_chan in enumerate(changes):\n",
    "        for i_x in range(Nx):\n",
    "            changes_x = 0\n",
    "            if (i_x not in changes):\n",
    "                for k in range(K):\n",
    "                    \n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[j_j]\n",
    "                    else:\n",
    "                        chan_new = changes[j_j]\n",
    "                        \n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    L_c_v1v2[j_j,i_x] += A_f[k,p2_2,p1_2]\n",
    "                \n",
    "                valor_lnew_2=1/K* L_c_v1v2[j_j,i_x]\n",
    "                L_c_v1v2[j_j,i_x] = round( valor_lnew_2)\n",
    "\n",
    "                    \n",
    "            else: # the changes are the same as the columns\n",
    "                changes_x = 1\n",
    "                if (i_x == j_chan):\n",
    "                    L_c_v1v2[j_j,i_x] =  L_f_v1v2[j_j,i_x]\n",
    "                else:\n",
    "                    i_x_inv = changes[j_j]\n",
    "                    if (j_j  == 0):\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[1,i_x_inv]\n",
    "\n",
    "                    else:\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[0,i_x_inv]\n",
    "           \n",
    "    suma_new = np.sum(L_f_v1v2[0,:]) + np.sum(L_f_v1v2[1,:]) + np.sum(L_c_v1v2[0,:]) + np.sum(L_c_v1v2[1,:])-L_c_v1v2[0,j_change]-L_c_v1v2[0,i_change]-L_c_v1v2[1,j_change]-L_c_v1v2[1,i_change]\n",
    "    suma_1 = suma_new - suma_old\n",
    "    return L_f_v1v2,L_c_v1v2, suma_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5b00922",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython = True)\n",
    "def parallel_L_knwn_change(c_parallel,alpha,beta,fijado_f,groups_f, N_groups_f, start_f, end_f,\n",
    "                       A, P_t_f, P_inv_t_f, L_t_f,suma_L, Energy_t_f, ovlp_t_f0, ovlp_t_f1, tempers_f):\n",
    "    \n",
    "    # fijado_f : To let one of the networks fixed or not (If only two networks it doesn't matter)\n",
    "    # c_parallel: counter to change temperatures\n",
    "    # start_f, end,f\n",
    "    # N_groups_f: Number of groups\n",
    "    # groups_f: Directly the ggroup numbeer from the position\n",
    "    \n",
    "    ### Movement:\n",
    "    # 1) Choose one node and see their group (also we can choose a group first)\n",
    "    # 2) Choose another random node inside this group \n",
    "    # 3) Each 4 movements, we propose change the temperatures\n",
    "\n",
    "    N_t = L_t_f.shape[0] # Numbers of tempers\n",
    "    Nx = L_t_f.shape[1] # Numbers of nodes\n",
    "    K = A.shape[0] # Numbers of networks\n",
    "    Edges_sum = K*Nx*Nx\n",
    "   \n",
    "    if (c_parallel <4*Nx): # If not change of temperatures\n",
    "        c_parallel += 1\n",
    "        \n",
    "        #Choose the networks to propose the change (in all temperatures)\n",
    "        if (fijado_f == 1):\n",
    "            m1 = np.random.randint(K-1)+1 #One networks\n",
    "        else:\n",
    "            m1 = np.random.randint(K)    \n",
    "        \n",
    "        for k_nt in range(N_t):            \n",
    "            # 1) Choose a random node (node in A)\n",
    "            v1_mapping = np.random.randint(start_f[0], Nx)\n",
    "            # Inside the group:\n",
    "            grupo = groups_f[k_nt,m1,v1_mapping]\n",
    "            start, end = start_f[grupo], end_f[grupo]\n",
    "            size_group = end - start\n",
    "            todos = size_group \n",
    "            if (size_group > 1): \n",
    "\n",
    "                v2_mapping = np.random.randint(start, end)\n",
    "                while (v2_mapping == v1_mapping):\n",
    "                    v2_mapping = np.random.randint(start, end)\n",
    "\n",
    "                # Nodes in L\n",
    "                v1 = P_t_f[k_nt, m1,v1_mapping]\n",
    "                v2 = P_t_f[k_nt, m1, v2_mapping]\n",
    "\n",
    "\n",
    "                ### Only changes in the specific columns and rows\n",
    "                L_f_v1v2, L_f_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "                L_c_v1v2, L_c_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "\n",
    "                pp_1 = int(P_inv_t_f[k_nt,m1,v2]) # v2_mapping\n",
    "                pp_2 = int(P_inv_t_f[k_nt,m1,v1]) # v1_mapping\n",
    "                \n",
    "                # Changes in the blueprint\n",
    "                L_f_v1v2,L_c_v1v2 , suma_aux = L_wiring_change_filas(m1,L_t_f[k_nt,:,:], A, v1, v2, P_inv_t_f[k_nt,:,:])\n",
    "                L_f_v1v2_old[0,:],L_f_v1v2_old[1,:] = L_t_f[k_nt,v1,:].copy(),L_t_f[k_nt,v2,:].copy()\n",
    "                L_c_v1v2_old[0,:],L_c_v1v2_old[1,:] = L_t_f[k_nt,:,v1].copy(),L_t_f[k_nt,:,v2].copy()\n",
    "                \n",
    "                # Parameters to change\n",
    "                Edges_L = K*(suma_L[k_nt] + suma_aux)\n",
    "                Edges_NoL = Edges_sum - Edges_L\n",
    "                ovl_0_new, ovl_1_new = overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2 ,A,P_inv_t_f[k_nt,:,:], v1,v2, pp_1, pp_2)\n",
    "                overlap_0,overlap_1 = ovlp_t_f0[k_nt] + ovl_0_new, ovlp_t_f1[k_nt] + ovl_1_new\n",
    "                Energy_bucle = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "                dE_sampler = Energy_bucle - Energy_t_f[k_nt]\n",
    "                dE_t = dE_sampler\n",
    "\n",
    "\n",
    "                ### UPDATE\n",
    "                if (dE_t < 0):\n",
    "                    \n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:].copy(),L_f_v1v2[1,:].copy()\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:].copy(),L_c_v1v2[1,:].copy()\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "                elif (np.random.rand() < np.exp(-dE_t*tempers_f[k_nt])):\n",
    "\n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:].copy(),L_f_v1v2[1,:].copy()\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:].copy(),L_c_v1v2[1,:].copy()\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "    else: # Change in temperatures\n",
    "        c_parallel = 0 \n",
    "        \n",
    "        mt1 = np.random.randint(N_t)  #temper 1\n",
    "        mt2 =  np.random.randint(N_t) #temper 2\n",
    "        while (mt1 == mt2):\n",
    "            mt2 = np.random.randint(N_t)\n",
    "\n",
    "        Energy_1 = Energy_t_f[mt1]\n",
    "        Energy_2 = Energy_t_f[mt2] \n",
    "\n",
    "        dE_parallel = -(tempers_f[mt1]-tempers_f[mt2])*(Energy_1-Energy_2)\n",
    "        if (dE_parallel <0):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            # 1 --> 2\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "\n",
    "            # 2 --> 1\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "        elif (np.random.rand() < np.exp(-dE_parallel)):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            # 1 --> 2\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "\n",
    "            # 2 --> 1\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "    return c_parallel, P_t_f, P_inv_t_f,Energy_t_f, ovlp_t_f0, ovlp_t_f1, L_t_f, suma_L, groups_f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bc917",
   "metadata": {},
   "source": [
    "# Running MonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "078591b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fijado = 0 # To maintain fix the first network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6af79cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy with the reference mapping: 16019.663954670905\n",
      "overlap_0: 192861 /overlap_1: 4653\n",
      "%Overlaps: 98.41059470663265 %\n"
     ]
    }
   ],
   "source": [
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i]=i \n",
    "        P_inv_new[k,i]=i            \n",
    "L_new = np.zeros((Nx,Nx)) \n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) # Los edges=1 que tiene la matriz A\n",
    "Edges_NoL = Edges_sum - Edges_L #Los edges=0 que tiene la matriz A\n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "print('Energy with the reference mapping:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9804fc00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Energy with the reference mapping: 16019.663954670905\n",
      "overlap_0: 192861 /overlap_1: 4653\n",
      "%Overlaps: 98.41059470663265 %\n",
      "\n",
      "Initial energy with L = A[0]: 64.73048223888327\n",
      "\n",
      "ERROR! Session/line number was not unique in database. History logging moved to new session 3825\n",
      "Energy with L_wiring: 30986.88988929674\n",
      "overlaps 0: 193183 1: 307\n",
      "%Overlaps: 96.40565210459184 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|██████████████████▋               | 5500/10000 [1:17:13<1:06:36,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 5500 Energy (temper = 1): 16915.184968600195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████▌              | 6000/10000 [1:24:03<54:23,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6000 Energy (temper = 1): 16897.194787065615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████████████████████            | 6500/10000 [1:31:18<1:10:21,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 6500 Energy (temper = 1): 16917.2274449993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|█████████████████████████▏          | 7000/10000 [1:38:09<27:38,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7000 Energy (temper = 1): 16884.493865860073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████████████████████████         | 7500/10000 [1:45:38<36:55,  1.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 7500 Energy (temper = 1): 16922.741765028848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████▊       | 8000/10000 [1:54:01<16:24,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8000 Energy (temper = 1): 16887.171644867143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|██████████████████████████████▌     | 8500/10000 [2:00:40<13:48,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 8500 Energy (temper = 1): 16912.74675820343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████▍   | 9000/10000 [2:07:20<12:04,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9000 Energy (temper = 1): 16748.616975494828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|██████████████████████████████████▏ | 9500/10000 [2:14:37<07:30,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 9500 Energy (temper = 1): 16730.5220391935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 10000/10000 [2:21:47<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed (after compilation) = 8507.755538702011\n",
      "Energy final: [17439.94461348 17210.50033007 17136.74327171 16925.47612803\n",
      " 16735.89129109 16428.19141348 16317.37276189 16255.26062544\n",
      " 16277.01804387 16209.1655681  16168.5395011  16082.16878821\n",
      " 15868.34373876 15879.13058339 15801.34677176] /Computed final: [17439.94461348 17210.50033007 17136.74327171 16925.47612803\n",
      " 16735.89129109 16428.19141348 16317.37276189 16255.26062544\n",
      " 16277.01804387 16209.1655681  16168.5395011  16082.16878821\n",
      " 15868.34373876 15879.13058339 15801.34677176]\n",
      "overlaps_0: 192714 overlap_1: 4390 %overlaps: 98.20631377551021 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed( random.randint(1,1999))\n",
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i]=i \n",
    "        P_inv_new[k,i]=i            \n",
    "L_new = np.zeros((Nx,Nx))\n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) # edges=1 in A\n",
    "Edges_NoL = Edges_sum - Edges_L # edges=0 in A\n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "print('Energy with the reference mapping:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n",
    "\n",
    "\n",
    "# VARIABLE USING INITIAL CONDITIONS\n",
    "P_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_t = np.zeros((N_t,K,Nx))\n",
    "L_t = np.zeros((N_t,Nx, Nx))\n",
    "Energy_t, Energy_ini_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "Edges_L_t, Edges_NoL_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "groups_t = np.zeros((N_t, K, Nx))\n",
    "ovlp_ini0_t = np.zeros((N_t)) + ovlp_ini0\n",
    "ovlp_ini1_t = np.zeros((N_t)) + ovlp_ini1\n",
    "ovlp_ini0_t, ovlp_ini1_t = ovlp_ini0_t.astype(int), ovlp_ini1_t.astype(int)\n",
    "ovlp_t0, ovlp_t1 = np.zeros((N_t)) + ovlp_ini0, np.zeros((N_t)) + ovlp_ini1\n",
    "P_t = (P_ini_t).copy()\n",
    "P_inv_t = (P_inv_ini_t).copy()\n",
    "L_t = (L_ini_t).copy()\n",
    "groups_t = groups_ini_t.copy()\n",
    "#Integer variables\n",
    "ovlp_t0, ovlp_t1 = ovlp_t0.astype(int), ovlp_t1.astype(int)\n",
    "P_t = P_t.astype(int)\n",
    "P_inv_t = P_inv_t.astype(int)\n",
    "L_t = L_t.astype(int)\n",
    "groups_t = groups_t.astype(int)\n",
    "\n",
    "## Initial energy with L = A[0]\n",
    "Edges_L = K*sum(sum(L_ini))\n",
    "Edges_NoL = Edges_sum - Edges_L            \n",
    "Energy_ini = hamiltonian_prob(Edges_NoL, Edges_L, ovlp_ini0, ovlp_ini1 ,alpha, beta)\n",
    "Energy_ini_t = np.zeros((N_t))+ Energy_ini \n",
    "print()\n",
    "print('Initial energy with L = A[0]:', Energy_ini)\n",
    "print()\n",
    "\n",
    "\n",
    "#### Now the Blueprint is averaged\n",
    "for k_nt in range(N_t):\n",
    "    L_t[k_nt,:,:] =  L_wiring(A, P_inv_t[k_nt,:,:])\n",
    "    Edges_L_t[k_nt] = K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL_t[k_nt] = Edges_sum - Edges_L_t[k_nt]\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_t[k_nt] = hamiltonian_prob(Edges_NoL_t[k_nt], Edges_L_t[k_nt], overlap_0, overlap_1,alpha, beta)\n",
    "    ovlp_t0[k_nt], ovlp_t1[k_nt] = overlap_0, overlap_1\n",
    "print('Energy with L_wiring:', Energy_t[0]) \n",
    "print('overlaps 0:', ovlp_t0[0], '1:', ovlp_t1[0])\n",
    "print('%Overlaps:',100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n",
    "Energy_ini_wiring = Energy_t.copy()\n",
    "suma_L_t = np.zeros(N_t)\n",
    "for k_nt in range(N_t):\n",
    "    suma_L_t[k_nt] = sum_numba(L_t[k_nt,:,:])\n",
    "\n",
    "\n",
    "### MONTE CARLO\n",
    "# Parameters\n",
    "PasosMC = 10000\n",
    "Long_corr = 500\n",
    "Pasos_corr = 5000\n",
    "Pasos_store = int((PasosMC - Pasos_corr)/Long_corr)\n",
    "if (Pasos_store<0):\n",
    "    Pasos_store = 0\n",
    "steps_middle_0 = 500\n",
    "steps_middle_1 = 1000\n",
    "    \n",
    "# Variables to store    \n",
    "energies_pasos = np.zeros((N_t,PasosMC))\n",
    "energies_pasos[:,0] = Energy_ini_wiring\n",
    "count_parallel, count_unl = 0, 0\n",
    "P_store = np.zeros((Pasos_store,N_t, K, Nx))\n",
    "groups_store = np.zeros((Pasos_store, N_t,K,Nx))\n",
    "Energy_store = np.zeros((Pasos_store, N_t))\n",
    "L_store = np.zeros((Pasos_store,N_t, Nx, Nx))\n",
    "P_intermediate_shot = np.zeros((2,N_t,K,Nx))\n",
    "E_intermediate_shot = np.zeros((2,N_t))\n",
    "\n",
    "\n",
    "#######################################\n",
    "start = time.time()\n",
    "count_parallel, count_long, i_long = 0,0,0\n",
    "for i_mc in tqdm(range(0,PasosMC)):\n",
    "    ## Starting to store sampling configurations\n",
    "    if (i_mc > Pasos_corr):\n",
    "        count_long += 1\n",
    "        if (count_long == Long_corr):\n",
    "            count_long = 0\n",
    "            P_store[i_long,:,:,:] = P_t.copy()\n",
    "            Energy_store[i_long,:] = Energy_t.copy()\n",
    "            L_store[i_long,:,:,:] = L_t.copy()\n",
    "            groups_store[i_long, :,:] = groups_t.copy()\n",
    "            i_long += 1\n",
    "            print('Step', i_mc, 'Energy (temper = 1):', Energy_t[4])\n",
    "    \n",
    "    ## Store transient configurations\n",
    "    if (i_mc == steps_middle_0 ):\n",
    "        P_intermediate_shot[0,:,:,:] = P_t.copy()\n",
    "        E_intermediate_shot[0,:] = Energy_t.copy()\n",
    "    if (i_mc == steps_middle_1 ):\n",
    "        P_intermediate_shot[1,:,:,:] = P_t.copy()\n",
    "        E_intermediate_shot[1,:] = Energy_t.copy()\n",
    "\n",
    "\n",
    "    energies_pasos[:, i_mc] = Energy_t[:]\n",
    "    for i_micro in range(Nx):\n",
    "\n",
    "        count_parallel,P_t, P_inv_t, Energy_t, ovlp_t0, ovlp_t1, L_t,suma_L_t, groups_t = parallel_L_knwn_change( count_parallel,alpha,beta,fijado,groups_t,n_groups, start_groups, \n",
    "                                                                                                 end_groups, A, P_t, P_inv_t, L_t,suma_L_t, Energy_t, ovlp_t0, \n",
    "                                                                                                 ovlp_t1, tempers)\n",
    "\n",
    "                                                                                                  \n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))  \n",
    "\n",
    "## Final energy\n",
    "Energy_calculada = np.zeros((N_t))\n",
    "for k_nt in range(N_t):\n",
    "    Edges_L= K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL = Edges_sum - Edges_L\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_calculada[k_nt] = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "    \n",
    "print('Energy final:', Energy_t, '/Computed final:', Energy_calculada) \n",
    "print('overlaps_0:', ovlp_t0[0], 'overlap_1:', ovlp_t1[0], '%overlaps:', 100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96685938",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'energies_pasos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m d_store\u001b[38;5;241m=\u001b[39m{}\n\u001b[1;32m      3\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcelegant_normal_k4_w_0.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m d_store[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDatos_energy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43menergies_pasos\u001b[49m\n\u001b[1;32m      5\u001b[0m d_store[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermus\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m P_t\n\u001b[1;32m      6\u001b[0m d_store[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPermus_inv\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m P_inv_t\n",
      "\u001b[0;31mNameError\u001b[0m: name 'energies_pasos' is not defined"
     ]
    }
   ],
   "source": [
    "# Voy a construir un diccionario para guardar todo\n",
    "d_store={}\n",
    "string = \"celegant_normal_k4_w_0.pickle\"\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"Permus_inv\"] = P_inv_t\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "\n",
    "d_store[\"P_inter\"] = P_intermediate_shot\n",
    "d_store[\"E_inter\"] = E_intermediate_shot\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "d_store[\"L_store\"] = L_store\n",
    "\n",
    "d_store[\"E_groundtruth\"] = Energy_new\n",
    "d_store[\"Pasos_corr_ini\"] = Pasos_corr \n",
    "d_store[\"Step_corr\"] = Long_corr \n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "# prueba = pickle.load(open(string, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3fdfc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voy a construir un diccionario para guardar todo\n",
    "d_store={}\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"Permus_inv\"] = P_inv_t\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "\n",
    "\n",
    "\n",
    "d_store[\"P_inter\"] = P_intermediate_shot\n",
    "d_store[\"E_inter\"] = E_intermediate_shot\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "d_store[\"L_store\"] = L_store\n",
    "\n",
    "d_store[\"E_groundtruth\"] = Energy_new\n",
    "d_store[\"Pasos_corr_ini\"] = Pasos_corr \n",
    "d_store[\"Step_corr\"] = Long_corr \n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "prueba = pickle.load(open(string, \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be925fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tempers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80b6c39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
