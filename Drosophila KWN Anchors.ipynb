{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c69eba05",
   "metadata": {},
   "source": [
    "# Drosophila larva with Anchors information\n",
    "\n",
    "In this case we align the right-left hemisphere of the Drosophila larva (only the neurons whose pair between hemisphere were known, we did a filtering process).\n",
    "\n",
    "The the neuron-type information will be used as group information for running the Parallel tempering MonteCarlo only proposing changes among nodes in the same group. \n",
    "\n",
    "The nodes-anchors are given by the experimental results. These nodes won't participate in the monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eefb8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "from numba import jit, njit\n",
    "from numba.types import bool_, int_, float32\n",
    "from math import comb\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from itertools import permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047abf06-3f44-4103-af88-4985c90d63d9",
   "metadata": {},
   "source": [
    "## DATA \n",
    "\n",
    "We download the data from our filtering process, and then transform the connectome in binary matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c848c94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_store = pickle.load(open(\"Drosophila_Hemispheres_allign_def.pickle\", \"rb\"))\n",
    "R_groups = d_store[\"Right\"]\n",
    "L_groups = d_store[\"Left\"] \n",
    "\n",
    "R_label = d_store[\"R_labels\"] \n",
    "L_label = d_store[\"L_labels\"] \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0d8624d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tablas = 2\n",
    "rows, columns = L_groups.shape[0] , R_groups.shape[0]\n",
    "M = np.zeros((tablas,rows,columns))\n",
    "\n",
    "M[0,:,:] = R_groups.copy()\n",
    "M[1,:,:] = L_groups.copy()\n",
    "\n",
    "## We work with square, binay matrices\n",
    "M_square = np.zeros((tablas, rows, rows))\n",
    "M_square[:,:, 0:columns] = M[:,:,:]\n",
    "\n",
    "M_bin = np.zeros((tablas,rows,columns))\n",
    "M_square_bin = np.zeros((tablas,rows,rows))\n",
    "for i in range(tablas):\n",
    "    for j in range(rows):\n",
    "        for k in range(columns):\n",
    "            if (M[i,j,k] >= 1):\n",
    "                M_bin[i,j,k] = 1\n",
    "                M_square_bin[i,j,k] = 1\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955c46f",
   "metadata": {},
   "source": [
    "## Functions\n",
    "\n",
    "Fucntions used to compute the energy of the alignments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9c655689",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "# Overlap deoend in the permutation!\n",
    "def overlap_total_prob(L_f, A_f, P_inv_f):\n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    ovlp_0, ovlp_1 = 0,0\n",
    "    for k in range(0,K):\n",
    "        for f in range(0,Ny):\n",
    "            for c in range(0,Nx):\n",
    "                p_f = int(P_inv_f[k,f])\n",
    "                p_c = int(P_inv_f[k,c])  \n",
    "                \n",
    "                valor_L, valor_A = L_f[f,c], A_f[k,p_f,p_c]\n",
    "                \n",
    "                ovlp_0 = ovlp_0 + (1-valor_L)*(1-valor_A )\n",
    "                ovlp_1 = ovlp_1 + valor_L*valor_A\n",
    "                \n",
    "\n",
    "    return ovlp_0, ovlp_1\n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta):\n",
    "    A_1 = overlap_1 + alpha\n",
    "    B_1 = (Edges_L - overlap_1 + beta)\n",
    "    C_1 = Edges_L + alpha + beta\n",
    "    \n",
    "    A_0 = overlap_0 + alpha\n",
    "    B_0 = (Edges_NoL - overlap_0 + beta)\n",
    "    C_0 = Edges_NoL + alpha + beta\n",
    "    \n",
    "    # !!!! Numba: [ math.lgamma(n+1) == log(n!) ]\n",
    "    H1 = math.lgamma(A_1)+ math.lgamma(B_1) - math.lgamma(C_1) \n",
    "    H0 = math.lgamma(A_0)+ math.lgamma(B_0) - math.lgamma(C_0) \n",
    "    \n",
    "    H = -(H1 + H0)\n",
    "\n",
    "    return H\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "#In each step the latent matrix is also stored\n",
    "def L_wiring(A_f, P_inv_f):\n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "    L_new_f = np.zeros((Nx,Ny))\n",
    "    \n",
    "    for i in range(0,Nx):\n",
    "        for j in range(0,Ny):\n",
    "            for k in range(0,K):\n",
    "                p1 = int(P_inv_f[k,i]) \n",
    "                p2 = int(P_inv_f[k,j]) \n",
    "                L_new_f[i,j] += A_f[k,p1,p2]\n",
    "            # Each entry averaged over all the network\n",
    "            valor_lnew=1/K* L_new_f[i,j]\n",
    "            L_new_f[i,j] = round( valor_lnew )\n",
    "\n",
    "    return L_new_f\n",
    "\n",
    "\n",
    "# Function to inizialise the problem, taking into account the node degree and the group information and the anchors\n",
    "@jit(nopython=True)\n",
    "def partition(array,  etiquetas, begin, end):\n",
    "    pivot = begin\n",
    "    for i in range(begin+1, end+1):\n",
    "        if array[i] < array[begin]:\n",
    "            pivot += 1\n",
    "            array[i], array[pivot] = array[pivot], array[i]\n",
    "            etiquetas[i], etiquetas[pivot] = etiquetas[pivot], etiquetas[i]\n",
    "    array[pivot], array[begin] = array[begin], array[pivot]\n",
    "    etiquetas[pivot], etiquetas[begin] = etiquetas[begin], etiquetas[pivot] \n",
    "\n",
    "    return pivot\n",
    "@jit(nopython=True)\n",
    "def quicksort(array, etiquetas, begin=0, end=None):\n",
    "    if end is None:\n",
    "        end = len(array) - 1\n",
    "    if begin >= end: \n",
    "        return\n",
    "    pivot = partition(array,  etiquetas, begin, end)\n",
    "    \n",
    "    #Order right and ledt\n",
    "    quicksort(array, etiquetas, begin, pivot-1)\n",
    "    quicksort(array,  etiquetas, pivot+1, end)\n",
    "\n",
    "\n",
    "def permu_groups_capa1_anchors_knwn(L_f, A_f, start_f,end_f,start_anch_f,end_anch_f,grupos_t, Anchors,grupos_extra): \n",
    "   \n",
    "    Nx = L_f.shape[0]\n",
    "    Ny = L_f.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    N_groups = len(start_f)\n",
    "    \n",
    "    start_anchor = start_anch_f.copy()\n",
    "    \n",
    "    end_anchor = end_anch_f.copy()\n",
    "    P_f = np.zeros((K,Nx))\n",
    "    P_inv_f = np.zeros((K,Nx))\n",
    "    P_new = np.zeros((K,Nx))\n",
    "    \n",
    "    n_an = len(Anchors)\n",
    "    P_inv_f[:,:n_an] = Anchors\n",
    "    \n",
    "    #Ordering accroding node degree Latent\n",
    "    orden_L_in = np.zeros((Nx-n_an ))\n",
    "    array_L = np.zeros((Nx-n_an ))\n",
    "    c_o = 0\n",
    "\n",
    "    for i in range(Nx):\n",
    "        if (i not in Anchors):\n",
    "            b = np.nonzero(L_f[i,:])\n",
    "            array_L[c_o] = i\n",
    "            orden_L_in[c_o] = b[0].size\n",
    "            c_o += 1\n",
    "     \n",
    "    orden_L = orden_L_in.copy()\n",
    "    quicksort(orden_L, array_L)\n",
    "    array_L = array_L[::-1]\n",
    "\n",
    "    grupos_L = np.zeros((Nx-n_an))\n",
    "    c_o = 0\n",
    "    for  i_g in range(N_groups):\n",
    "        for i_x in range(start_f[i_g], end_f[i_g]):\n",
    "            if i_x not in Anchors:\n",
    "                grupos_L[c_o] = i_g\n",
    "                c_o += 1\n",
    "    grupos_L = grupos_L.astype(int)\n",
    "    orden_L = orden_L_in.copy()\n",
    "    quicksort(orden_L, grupos_L )\n",
    "    grupos_L = grupos_L[::-1]\n",
    "\n",
    "    #Ordering connectomes\n",
    "    for i in range(0,K):\n",
    "        orden_A_in = np.zeros((Nx- n_an))\n",
    "        array_A = np.zeros((Nx-n_an))\n",
    "        grupos_A = np.zeros((Nx-n_an))\n",
    "        c_o = 0\n",
    "        for i_orden in range(Nx):\n",
    "            if (i_orden not in Anchors):\n",
    "                b = np.nonzero(A_f[i,i_orden,:])\n",
    "                array_A[c_o] = i_orden\n",
    "                grupos_A[c_o] = grupos_t[i, i_orden]\n",
    "                orden_A_in[c_o] = b[0].size#.size\n",
    "                c_o += 1\n",
    "        \n",
    "        orden_A = orden_A_in.copy()\n",
    "        quicksort(orden_A, array_A)  \n",
    "        array_A = array_A[::-1]\n",
    "\n",
    "        orden_A = orden_A_in.copy()\n",
    "        quicksort(orden_A, grupos_A)\n",
    "        grupos_A = grupos_A[::-1]\n",
    "\n",
    "        \n",
    "        array_A_L = np.zeros((Nx - n_an))\n",
    "        for i_n in range(Nx-n_an):\n",
    "            if ((grupos_A[i_n] == grupos_L[i_n])):\n",
    "                array_A_L[i_n] = array_A[i_n]\n",
    "            else:\n",
    "                # Look for the next one belonging to the same group\n",
    "                count = 0\n",
    "                for i_nn in range(i_n, Nx-n_an):\n",
    "                    if ((grupos_A[i_nn] == grupos_L[i_n])): \n",
    "                        array_A_L[i_n] = array_A[i_nn]\n",
    "                        array_A[i_nn] = array_A[i_n]\n",
    "                        aux = grupos_A[i_nn]\n",
    "                        grupos_A[i_nn] = grupos_A[i_n]\n",
    "                        grupos_A[i_n] = aux\n",
    "                        count = 1\n",
    "                        break\n",
    "        array_A_L = array_A_L[np.argsort(array_L)]\n",
    "        P_inv_f[i,n_an:] = array_A_L\n",
    "        \n",
    "        for i_inv in range(0,Nx):\n",
    "            for j_inv in range(0,Ny):\n",
    "                if (P_inv_f[i,i_inv] == j_inv):\n",
    "                    P_f[i, j_inv]=i_inv\n",
    "    \n",
    "    P_todo = np.zeros((2,K,Nx))\n",
    "    P_todo[0,:,:] = P_f.copy()\n",
    "    P_todo[1,:,:] = P_inv_f.copy()\n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    return P_todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4331825a",
   "metadata": {},
   "source": [
    "# Initial condition\n",
    "\n",
    "Now we initialize our problem with all the information we have: the group and the anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c5e011f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neuron types: ['sensory' 'LN' 'PN' 'DN-SEZ' 'ascending' 'pre-DN-VNC' 'PN-somato'\n",
      " 'pre-DN-SEZ' 'DN-VNC' 'RGN' 'LHN' 'KC' 'CN' 'MB-FFN' 'MB-FBN' 'MBON'\n",
      " 'MBIN']\n",
      "SIZE GROUPS: [197  54 103  82  23 238  76  51  91  27 101  23  50  27  54  24  14]\n",
      "Starting node of each group [   0  197  251  354  436  459  697  773  824  915  942 1043 1066 1116\n",
      " 1143 1197 1221]\n",
      "Last nodes [ 197  251  354  436  459  697  773  824  915  942 1043 1066 1116 1143\n",
      " 1197 1221 1235]\n"
     ]
    }
   ],
   "source": [
    "start_groups = d_store[\"start_groups\"]\n",
    "end_groups = d_store[\"end_groups\"] \n",
    "size_groups = d_store[\"size_groups\"]\n",
    "names_groups = d_store[\"name_groups\"] \n",
    "\n",
    "n_groups = len(size_groups)\n",
    "\n",
    "print('Neuron types:',names_groups)\n",
    "print('SIZE GROUPS:', size_groups)\n",
    "\n",
    "print('Starting node of each group', start_groups)\n",
    "print('Last nodes', end_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32ce360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nodes\n",
    "Nx, Ny = rows, rows \n",
    "#Connectomes\n",
    "K = 2 \n",
    "alpha,beta = 5,2 #Beta distribution\n",
    "Edges = Nx*Ny #Entries of the Latent matrix\n",
    "micropasos = Edges*K #Microsteps in MonteCarlo\n",
    "\n",
    "np.random.seed(np.random.randint(199))\n",
    "A = np.zeros((K,Nx,Ny))\n",
    "A = M_square_bin[:, :,:]\n",
    "\n",
    "\n",
    "####################################\n",
    "## INITIALISE ##\n",
    "L_ini = np.zeros((Nx,Ny))\n",
    "P_ini_0 = np.zeros((K,Nx))\n",
    "P_inv_ini_0 = np.zeros((K,Nx))\n",
    "L_ini = (A[0,:,:]).copy()\n",
    "\n",
    "groups_ini = np.zeros((K,Nx))\n",
    "for m1 in range(K):\n",
    "    for i_g in range(n_groups):\n",
    "        start = start_groups[i_g]\n",
    "        end = end_groups[i_g]\n",
    "        groups_ini[m1, start:end] = i_g"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3cf01",
   "metadata": {},
   "source": [
    "# Anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "98b6372d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_anchor = d_store[\"start_anchors\"] \n",
    "end_anchor = d_store[\"end_anchor\"] \n",
    "grupos_extra = d_store[\"anchors_group\"] \n",
    "Anchors = d_store[\"anchors_all\"] \n",
    "\n",
    "groups_ini_anchor = np.zeros((K,Nx))-1\n",
    "for m1 in range(K):\n",
    "    for i_g in range(n_groups):\n",
    "        start = start_anchor[i_g]\n",
    "        end = end_anchor[i_g]\n",
    "        groups_ini_anchor[m1, start:end] = i_g\n",
    "\n",
    "P_inis = permu_groups_capa1_anchors_knwn(L_ini, A, start_groups,end_groups,start_anchor,end_anchor,groups_ini, Anchors, grupos_extra) \n",
    "P_inis = P_inis.astype(int)\n",
    "P_ini_0 = (P_inis[0,:,:]).copy()#\n",
    "P_inv_ini_0 = (P_inis[1,:,:]).copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ea5703",
   "metadata": {},
   "source": [
    "## Temperatures for the Parallel tempering\n",
    "\n",
    "Tempers account for the betas (1/T) in Boltzmann distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28c07022",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_o = 1.03\n",
    "total = 15\n",
    "b_exp = np.linspace(-5,5,num = total)\n",
    "tempers = beta_o**b_exp\n",
    "N_t = len(tempers)\n",
    "\n",
    "#Initialization\n",
    "P_ini_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_ini_t = np.zeros((N_t,K,Nx))\n",
    "L_ini_t = np.zeros((N_t,Nx,Ny)) \n",
    "groups_ini_t = np.zeros((N_t, K, Nx ))\n",
    "groups_anch_ini_t = np.zeros((N_t, K, Nx ))\n",
    "\n",
    "for i in range(0,N_t): #Aquí estoy inicializando para las temperaturas\n",
    "    P_ini_t[i,:,:] = P_ini_0[:,:].copy()\n",
    "    P_inv_ini_t[i,:,:] = P_inv_ini_0[:,:].copy()\n",
    "    L_ini_t[i,:,:] = L_ini.copy()\n",
    "    groups_ini_t[i,:,:] = groups_ini.copy()\n",
    "    groups_anch_ini_t[i,:,:] = groups_ini_anchor.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060faab1",
   "metadata": {},
   "source": [
    "# Functions for the main MonteCarlo Parallel tempering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b37dd418",
   "metadata": {},
   "outputs": [],
   "source": [
    "## FUNCTIONS NEEDED FOR NUMBA\n",
    "\n",
    "@njit\n",
    "def concatenate_numba_sinrep(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    no_double = []\n",
    "    for i_b in range(size_b):\n",
    "        if b[i_b] in a:\n",
    "            size_b = size_b-1\n",
    "        else:\n",
    "            no_double.append(b[i_b])\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = no_double\n",
    "    \n",
    "    return a\n",
    "\n",
    "@njit\n",
    "def concatenate_numba(a,b):\n",
    "    size_a, size_b = len(a), len(b)\n",
    "    size = size_a + size_b\n",
    "    c = np.zeros((size))\n",
    "    c[0:size_a] = a\n",
    "    c[size_a:] = b \n",
    "    \n",
    "    return c\n",
    "\n",
    "@njit\n",
    "def sum_numba(S):\n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    \n",
    "    suma = 0\n",
    "    for i_s in range(Nx):\n",
    "        suma = suma + sum(S[i_s,:])\n",
    "        \n",
    "    return suma\n",
    "@njit\n",
    "def sum_numba_filas(S): \n",
    "    Nx = S.shape[0]\n",
    "    Ny = S.shape[1]\n",
    "    suma = np.zeros((Nx))\n",
    "    for i_s in range(Nx):\n",
    "        suma_c = 0 \n",
    "        for i_y in range(Ny):\n",
    "            suma[i_s] = suma_c + S[i_y,i_s] \n",
    "        \n",
    "    return suma\n",
    "\n",
    "@njit\n",
    "def custom_round(number):\n",
    "    if number >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "@njit\n",
    "def random_menos_mas(number):\n",
    "    if number >= 0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fdee8589",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FUNCTIONS TO UPDATE OVERLAPS AND ENERGY WHEN A CHANGE IS PROPOSED\n",
    "\n",
    "@jit(nopython=True)\n",
    "def overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2,A_f, P_inv_old, i_change, j_change,pp1, pp2): \n",
    "\n",
    "    Nx = L_f_v1v2_old.shape[1]\n",
    "    K = A_f.shape[0]\n",
    "    \n",
    "    ovlp_0_new , ovlp_1_new = 0,0\n",
    "    ovlp_0_old , ovlp_1_old = 0,0\n",
    "    ovlp_0_dif, ovlp_1_dif = 0,0\n",
    "  \n",
    "    \n",
    "    changes = np.array([i_change, j_change], dtype = np.int32)\n",
    "    changes_p = np.array([pp1, pp2], dtype = np.int32)\n",
    "    changes_p_old = np.array([pp2, pp1], dtype = np.int32)\n",
    "\n",
    "    for i_k in range(K):\n",
    "        for i_chan,change in enumerate(changes):\n",
    "            for i_x in range(Nx):\n",
    "                if (i_k != m1):\n",
    "                    p_f = int(P_inv_old[i_k,change])\n",
    "                    p_c = int(P_inv_old[i_k,i_x])\n",
    "                    p_old, p_old_c = p_f, p_c\n",
    "                \n",
    "                else:\n",
    "                    p_f = changes_p[i_chan]\n",
    "                    p_old = changes_p_old[i_chan]\n",
    "\n",
    "                    if (i_x == i_change):\n",
    "                        p_c = pp1\n",
    "                        p_old_c = pp2\n",
    "                    elif(i_x == j_change):\n",
    "                        p_c = pp2\n",
    "                        p_old_c = pp1\n",
    "                    else:\n",
    "                        p_c = int(P_inv_old[i_k, i_x])\n",
    "                        p_old_c = p_c\n",
    "\n",
    "                ### ROWS\n",
    "                valor_L_old, valor_A_old = L_f_v1v2_old[i_chan,i_x], A_f[i_k,p_old,p_old_c]\n",
    "                \n",
    "                valor_L_new, valor_A_new = L_f_v1v2[i_chan,i_x], A_f[i_k,p_f,p_c]\n",
    "\n",
    "                # COLUMNS\n",
    "                column = 0\n",
    "                if (i_x not in changes):\n",
    "                    column = 1\n",
    "                    valor_L_old_c, valor_A_old_c = L_c_v1v2_old[i_chan,i_x],A_f[i_k,p_old_c, p_old]\n",
    "                    valor_L_new_c, valor_A_new_c = L_c_v1v2[i_chan,i_x], A_f[i_k,p_c,p_f]\n",
    "\n",
    "                ovlp_1_old = ovlp_1_old + valor_L_old*valor_A_old + valor_L_old_c*valor_A_old_c*column\n",
    "                ovlp_0_old = ovlp_0_old + (1-valor_L_old)*(1-valor_A_old) + (1-valor_L_old_c)*(1-valor_A_old_c)*column\n",
    "                \n",
    "                ovlp_1_new = ovlp_1_new + valor_L_new*valor_A_new + valor_L_new_c*valor_A_new_c*column\n",
    "                ovlp_0_new = ovlp_0_new + (1-valor_L_new)*(1-valor_A_new) + (1-valor_L_new_c)*(1-valor_A_new_c)*column\n",
    "                \n",
    "    ovlp_1_def = ovlp_1_new - ovlp_1_old\n",
    "    ovlp_0_def = ovlp_0_new- ovlp_0_old\n",
    "\n",
    "    return ovlp_0_def, ovlp_1_def\n",
    "\n",
    "\n",
    "##Changes in the rows and columns for the changing\n",
    "@jit(nopython=True)\n",
    "def L_wiring_change_filas(m1,L_old,A_f, i_change, j_change, P_inv_old):\n",
    "    \n",
    "    Nx = A_f.shape[1]\n",
    "    Ny = A_f.shape[2]\n",
    "    K = A_f.shape[0]\n",
    "\n",
    "    changes = np.array([i_change, j_change])\n",
    "    changes_new = np.array([j_change, i_change])\n",
    "    \n",
    "    L_new_f = L_old.copy()\n",
    "    L_f_v1v2,L_c_v1v2  = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "    L_new_f[i_change,:], L_new_f[j_change,:], L_new_f[:,i_change], L_new_f[:,j_change] = np.zeros(Nx),np.zeros(Nx),np.zeros(Nx),np.zeros(Nx)\n",
    "\n",
    "    # Old \n",
    "    suma_old =(np.sum(L_old[i_change,:]) + np.sum(L_old[j_change,:]) + np.sum(L_old[:,i_change]) + np.sum(L_old[:,j_change]))-L_old[i_change,j_change]-L_old[j_change,j_change]-L_old[i_change,i_change]-L_old[j_change,i_change]\n",
    "\n",
    "    # New, ROWS\n",
    "    suma_1 = 0\n",
    "    for i_i,i_chan in enumerate(changes):\n",
    "        for i_x in range(Nx):\n",
    "            if (i_x not in changes ):\n",
    "                for k in range(K):\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "\n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "\n",
    "            else:\n",
    "                for k in range(K):\n",
    "\n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[i_i]\n",
    "                        \n",
    "                        if (i_x == changes_new[0]):\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[1]])\n",
    "                        else:\n",
    "                            p2_2 = int(P_inv_old[k,changes_new[0]])\n",
    "                    else:\n",
    "                        chan_new = changes[i_i]\n",
    "                        p2_2 = int(P_inv_old[k,i_x])\n",
    "\n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "\n",
    "                    L_f_v1v2[i_i,i_x] += A_f[k,p1_2,p2_2]\n",
    "            # Average      \n",
    "            valor_lnew_2=1/K*  L_f_v1v2[i_i,i_x]\n",
    "            L_f_v1v2[i_i,i_x] = round( valor_lnew_2 )\n",
    "      \n",
    "                    \n",
    "    ## New, COLUMNs (no crossings )\n",
    "    for j_j,j_chan in enumerate(changes):\n",
    "        for i_x in range(Nx):\n",
    "            changes_x = 0\n",
    "            if (i_x not in changes):\n",
    "                for k in range(K):\n",
    "                    \n",
    "                    if (k == m1):\n",
    "                        chan_new = changes_new[j_j]\n",
    "                    else:\n",
    "                        chan_new = changes[j_j]\n",
    "                        \n",
    "                    p1_2 = int (P_inv_old[k,chan_new])\n",
    "                    p2_2 = int(P_inv_old[k,i_x])\n",
    "                    L_c_v1v2[j_j,i_x] += A_f[k,p2_2,p1_2]\n",
    "                \n",
    "                valor_lnew_2=1/K* L_c_v1v2[j_j,i_x]\n",
    "                L_c_v1v2[j_j,i_x] = round( valor_lnew_2)\n",
    "\n",
    "                    \n",
    "            else:\n",
    "                changes_x = 1\n",
    "                if (i_x == j_chan):\n",
    "                    L_c_v1v2[j_j,i_x] =  L_f_v1v2[j_j,i_x]\n",
    "                else:\n",
    "                    i_x_inv = changes[j_j]\n",
    "                    if (j_j  == 0):\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[1,i_x_inv]\n",
    "\n",
    "                    else:\n",
    "                        L_c_v1v2[j_j,i_x] =  L_f_v1v2[0,i_x_inv]\n",
    "           \n",
    "    suma_new = np.sum(L_f_v1v2[0,:]) + np.sum(L_f_v1v2[1,:]) + np.sum(L_c_v1v2[0,:]) + np.sum(L_c_v1v2[1,:])-L_c_v1v2[0,j_change]-L_c_v1v2[0,i_change]-L_c_v1v2[1,j_change]-L_c_v1v2[1,i_change]\n",
    "    \n",
    "    suma_1 = suma_new - suma_old\n",
    "    \n",
    "    return L_f_v1v2,L_c_v1v2, suma_1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc7156e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main Monte Carlo\n",
    "@jit(nopython = True)\n",
    "def parallel_groups(c_parallel,fijado_f, N_groups, groups_f, start_f, end_f,A, P_t_f, P_inv_t_f, L_t_f, suma_L,\n",
    "                      Energy_t_f, ovlp_t_f0, ovlp_t_f1,tempers_f, i_mc):\n",
    "\n",
    "    \n",
    "    alpha,beta = 5,2\n",
    "    N_t = L_t_f.shape[0]\n",
    "    Nx = L_t_f.shape[1]\n",
    "    K = A.shape[0]\n",
    "    Edges_sum = K*Nx*Nx\n",
    "    N_t_f = len(tempers_f)\n",
    "\n",
    "    if (c_parallel < 4*Nx): \n",
    "        c_parallel += 1\n",
    "        if (fijado_f == 1):\n",
    "            m1 = np.random.randint(K-1)+1 # To fix the first layer\n",
    "        else:\n",
    "            m1 = np.random.randint(K)    \n",
    "        \n",
    "        for k_nt in range(N_t):\n",
    "\n",
    "            #Movement not in the anchors\n",
    "            v1 = np.random.randint(start_f[0], Nx)\n",
    "            grupo = groups_f[k_nt,m1,v1] #Movement inside the group\n",
    "            start, end = start_f[grupo], end_f[grupo]\n",
    "            if ((end-start) != 0): #Groups with more than one node\n",
    "                \n",
    "                v2 = np.random.randint(start, end)\n",
    "                while (v2 == v1):\n",
    "                    v2 = np.random.randint(start, end)\n",
    "\n",
    "                v1_mapping = P_inv_t_f[k_nt, m1, v1]\n",
    "                v2_mapping = P_inv_t_f[k_nt, m1, v2]\n",
    "                \n",
    "                pp_1 = v2_mapping \n",
    "                pp_2 = v1_mapping \n",
    "\n",
    "                #Changes in L_wiring, Recalculating the nodes\n",
    "                L_f_v1v2, L_f_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "                L_c_v1v2, L_c_v1v2_old = np.zeros((2,Nx)),np.zeros((2,Nx))\n",
    "                L_f_v1v2,L_c_v1v2 , suma_aux = L_wiring_change_filas(m1,L_t_f[k_nt,:,:], A, v1, v2, P_inv_t_f[k_nt,:,:])   \n",
    "                L_f_v1v2_old[0,:],L_f_v1v2_old[1,:] = L_t_f[k_nt,v1,:],L_t_f[k_nt,v2,:]\n",
    "                L_c_v1v2_old[0,:],L_c_v1v2_old[1,:] = L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2]\n",
    "\n",
    "                Edges_L = K*(suma_L[k_nt] + suma_aux)\n",
    "                Edges_NoL = Edges_sum - Edges_L\n",
    "                ovl_0_new, ovl_1_new = overlap_total_change_filas(m1,L_f_v1v2_old,L_c_v1v2_old,L_f_v1v2,L_c_v1v2 ,A,P_inv_t_f[k_nt,:,:], v1,v2, pp_1, pp_2)\n",
    "                overlap_0,overlap_1 = ovlp_t_f0[k_nt] + ovl_0_new, ovlp_t_f1[k_nt] + ovl_1_new\n",
    "\n",
    "                Energy_bucle = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)  \n",
    "                dE_sampler = Energy_bucle - Energy_t_f[k_nt]\n",
    "                dE_t = dE_sampler\n",
    "       \n",
    "                if (dE_t <= 0):\n",
    "\n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:],L_f_v1v2[1,:]\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:],L_c_v1v2[1,:]\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "                elif (np.random.rand() < np.exp(-dE_t*tempers_f[k_nt])):\n",
    "\n",
    "                    P_aux1 = P_t_f[k_nt, m1,pp_2]\n",
    "                    P_t_f[k_nt, m1, pp_2] = P_t_f[k_nt, m1,pp_1]\n",
    "                    P_t_f[k_nt, m1, pp_1] = P_aux1\n",
    "\n",
    "                    P_invaux1 = P_inv_t_f[k_nt,m1,v2]\n",
    "                    P_inv_t_f[k_nt,m1,v2] = P_inv_t_f[k_nt,m1,v1]\n",
    "                    P_inv_t_f[k_nt,m1,v1] = P_invaux1\n",
    "\n",
    "                    Energy_t_f[k_nt] = Energy_t_f[k_nt] + dE_t\n",
    "                    ovlp_t_f0[k_nt] = overlap_0\n",
    "                    ovlp_t_f1[k_nt] = overlap_1\n",
    "                    L_t_f[k_nt,v1, :],L_t_f[k_nt,v2, :] = L_f_v1v2[0,:],L_f_v1v2[1,:]\n",
    "                    L_t_f[k_nt,:,v1],L_t_f[k_nt,:,v2] = L_c_v1v2[0,:],L_c_v1v2[1,:]\n",
    "                    suma_L[k_nt] = suma_L[k_nt] + suma_aux\n",
    "\n",
    "\n",
    "    else: #Change between adjacent temperatures\n",
    "        c_parallel = 0\n",
    "        # Only changes between adjacent temperatures\n",
    "        mt1 = np.random.randint(N_t_f) \n",
    "        if mt1 == 0:\n",
    "            mt2 = 1\n",
    "        elif mt1 == (N_t - 1):\n",
    "            mt2 = mt1 -1\n",
    "        else:\n",
    "            mt2 = mt1 + random_menos_mas(np.random.rand())\n",
    "            \n",
    "        Energy_1 = Energy_t_f[mt1]\n",
    "        Energy_2 = Energy_t_f[mt2] \n",
    "\n",
    "        dE_parallel = -(tempers_f[mt1]-tempers_f[mt2])*(Energy_1-Energy_2)\n",
    "        if (dE_parallel <= 0):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "            \n",
    "        elif (np.random.rand() < np.exp(-dE_parallel)):\n",
    "            P_aux1 = (P_t_f[mt1, :, :]).copy()\n",
    "            P_inv_aux1 = (P_inv_t_f[mt1,:,:]).copy()\n",
    "            L_aux1 = (L_t_f[mt1,:,:]).copy()\n",
    "            ovlp_aux0 = (ovlp_t_f0[mt1])\n",
    "            ovlp_aux1 = (ovlp_t_f1[mt1])\n",
    "            suma_aux = suma_L[mt1]\n",
    "\n",
    "            Energy_t_f[mt1] = Energy_2\n",
    "            P_t_f[mt1,:,:] = (P_t_f[mt2, :, :]).copy()\n",
    "            P_inv_t_f[mt1,:,:] = (P_inv_t_f[mt2,:,:]).copy()\n",
    "            L_t_f[mt1,:,:] = (L_t_f[mt2,:,:]).copy()\n",
    "            suma_L[mt1] = suma_L[mt2]\n",
    "            ovlp_t_f0[mt1] = ovlp_t_f0[mt2]\n",
    "            ovlp_t_f1[mt1] = ovlp_t_f1[mt2]\n",
    "\n",
    "            Energy_t_f[mt2] = Energy_1\n",
    "            P_t_f[mt2,:,:] = P_aux1.copy()\n",
    "            P_inv_t_f[mt2,:,:] = P_inv_aux1.copy()\n",
    "            L_t_f[mt2,:,:] = L_aux1.copy()\n",
    "            ovlp_t_f0[mt2] = ovlp_aux0\n",
    "            ovlp_t_f1[mt2] = ovlp_aux1\n",
    "            suma_L[mt2] = suma_aux\n",
    "\n",
    "    \n",
    "\n",
    "    return c_parallel, P_t_f, P_inv_t_f,Energy_t_f, ovlp_t_f0, ovlp_t_f1, L_t_f, suma_L"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26bc917",
   "metadata": {},
   "source": [
    "# Running MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "078591b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fijado = 0 #To fix or not fix the first connectome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d3c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Energy with the averaged L with the reference permutation: 144388.1567874623\n",
      "overlap_0: 2997012.0 /overlap_1: 28524.0\n",
      "%Overlaps: 99.18326804241997 %\n",
      "\n",
      "Initial Energy for L = A[0]: 263750.52790544706\n",
      "\n",
      "Initial Energy with L from WIRING: 229008.12801264034\n",
      "overlaps 0: 2997012 1: 9692\n",
      "%Overlaps: 98.56591650412234 %\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "## INITIALIZATION WITH THE Reference alignment\n",
    "\n",
    "P_new, P_inv_new = np.zeros((K,Nx)),np.zeros((K,Nx))\n",
    "for k in range(0,K):\n",
    "    for i in range(0,Nx):\n",
    "        P_new[k,i] = i \n",
    "        P_inv_new[k,i] = i            \n",
    "L_new = np.zeros((Nx,Ny)) \n",
    "L_new =  L_wiring(A, P_inv_new)\n",
    "\n",
    "Edges_sum = K*Nx*Nx\n",
    "Edges_L = K*(sum(sum(L_new))) \n",
    "Edges_NoL = Edges_sum - Edges_L \n",
    "overlap_0, overlap_1 = overlap_total_prob(L_new,A,P_inv_new)     \n",
    "Energy_new = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0, overlap_1, alpha, beta)\n",
    "Energy_ground_truth = Energy_new\n",
    "print('Initial Energy with the averaged L with the reference permutation:', Energy_new)\n",
    "print( 'overlap_0:', overlap_0,'/overlap_1:', overlap_1)\n",
    "print('%Overlaps:',100*(overlap_0+overlap_1)/Edges_sum ,'%')\n",
    "\n",
    "### INITIALIZATION WITH TEMPERATURES\n",
    "\n",
    "ovlp_ini0, ovlp_ini1 = overlap_total_prob(L_ini,A,P_inv_ini_0)\n",
    "ovlp_ini0_t = np.zeros((N_t)) + ovlp_ini0\n",
    "ovlp_ini1_t = np.zeros((N_t)) + ovlp_ini1\n",
    "ovlp_ini0_t, ovlp_ini1_t = ovlp_ini0_t.astype(int), ovlp_ini1_t.astype(int)\n",
    "\n",
    "P_t = np.zeros((N_t,K,Nx))\n",
    "P_inv_t = np.zeros((N_t,K,Nx))\n",
    "L_t = np.zeros((N_t,Nx, Ny))\n",
    "Energy_t, Energy_ini_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "Edges_L_t, Edges_NoL_t = np.zeros((N_t)), np.zeros((N_t))\n",
    "groups_t = np.zeros((N_t, K, Nx))\n",
    "groups_anch_t = np.zeros((N_t, K, Nx))\n",
    "ovlp_t0, ovlp_t1 = np.zeros((N_t)) + ovlp_ini0, np.zeros((N_t)) + ovlp_ini1\n",
    "P_t = (P_ini_t).copy()\n",
    "P_inv_t = (P_inv_ini_t).copy()\n",
    "L_t = (L_ini_t).copy()\n",
    "groups_t = groups_ini_t.copy()\n",
    "groups_anch_t = groups_anch_ini_t.copy()\n",
    "ovlp_t0, ovlp_t1 = ovlp_t0.astype(int), ovlp_t1.astype(int)\n",
    "P_t = P_t.astype(int)\n",
    "P_inv_t = P_inv_t.astype(int)\n",
    "L_t = L_t.astype(int)\n",
    "groups_t = groups_t.astype(int)\n",
    "groups_anch_t = groups_anch_t.astype(int)\n",
    "\n",
    "Edges_L = K*sum(sum(L_ini))\n",
    "Edges_NoL = Edges_sum - Edges_L            \n",
    "Energy_ini = hamiltonian_prob(Edges_NoL, Edges_L, ovlp_ini0, ovlp_ini1 ,alpha, beta)\n",
    "Energy_ini_t = np.zeros((N_t))+ Energy_ini \n",
    "print()\n",
    "\n",
    "print('Initial Energy for L = A[0]:', Energy_ini)\n",
    "print()\n",
    "\n",
    "#######################################\n",
    "start = time.time()\n",
    "count_mc = 0\n",
    "\n",
    "# Wiring\n",
    "for k_nt in range(N_t):\n",
    "    L_t[k_nt,:,:] =  L_wiring(A, P_inv_t[k_nt,:,:])\n",
    "    Edges_L_t[k_nt] = K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL_t[k_nt] = Edges_sum - Edges_L_t[k_nt]\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_t[k_nt] = hamiltonian_prob(Edges_NoL_t[k_nt], Edges_L_t[k_nt], overlap_0, overlap_1,alpha, beta)\n",
    "    ovlp_t0[k_nt], ovlp_t1[k_nt] = overlap_0, overlap_1\n",
    "\n",
    "suma_L_t = np.zeros(N_t)\n",
    "for k_nt in range(N_t):\n",
    "    suma_L_t[k_nt] = sum_numba(L_t[k_nt,:,:])\n",
    "    \n",
    "print('Initial Energy with L from WIRING:', Energy_t[0]) \n",
    "print('overlaps 0:', ovlp_t0[0], '1:', ovlp_t1[0])\n",
    "print('%Overlaps:',100*(ovlp_t0[0] + ovlp_t1[0])/Edges_sum ,'%')\n",
    "\n",
    "print()\n",
    "Energy_ini_wiring = Energy_t.copy()\n",
    "\n",
    "# Storing for statistics: \n",
    "\n",
    "runs = 2 #independent epochs\n",
    "PasosMC = 1 # Steps MC\n",
    "energies_pasos = np.zeros((N_t,PasosMC))\n",
    "energies_pasos[:,0] = Energy_ini_wiring\n",
    "count_parallel = 0\n",
    "\n",
    "Long_corr = 50 # Stored each 50 MCMC Steps\n",
    "Pasos_corr = 300 # Steps to thermalized\n",
    "Pasos_store = int((PasosMC - Pasos_corr)/Long_corr)\n",
    "if (Pasos_store<0):\n",
    "    Pasos_store = 0\n",
    "count_long, i_long = 0, 0 \n",
    "P_store = np.zeros((runs,Pasos_store,N_t, K, Nx))\n",
    "Energy_store = np.zeros((runs,Pasos_store, N_t))\n",
    "P_intermediate_shot = np.zeros((2,N_t,K,Nx))\n",
    "E_intermediate_shot = np.zeros((2,N_t))\n",
    "steps_middle_0 = 50\n",
    "steps_middle_1 = 100\n",
    "\n",
    "\n",
    "########################################################\n",
    "L_run, Edges_L_run, Edges_noL_run, ov0_run, ov1_run, E_run, suma_run, P_run, P_inv_run = L_t.copy(), Edges_L_t.copy(), Edges_NoL_t.copy(), ovlp_t0.copy(), ovlp_t1.copy(), Energy_t.copy(), suma_L_t.copy(),P_t.copy(), P_inv_t.copy()\n",
    "Edges_L_run, Edges_noL_run, ov0_run, ov1_run = Edges_L_run.astype(int), Edges_noL_run.astype(int), ov0_run.astype(int), ov1_run.astype(int)\n",
    "\n",
    "for i_epoch in range(runs):\n",
    "    L_t, ovlp_t0, ovlp_t1, Energy_t,suma_L_t,P_t, P_inv_t = L_run.copy(), ov0_run.copy(), ov1_run.copy(), E_run.copy(), suma_run.copy(), P_run.copy(), P_inv_run.copy()\n",
    "    i_long = 0\n",
    "    \n",
    "    for i_mc in tqdm(range(0,PasosMC)):\n",
    "    ### STORE\n",
    "        if (i_mc > Pasos_corr):\n",
    "            count_long += 1\n",
    "            if (count_long == Long_corr):\n",
    "                count_long = 0\n",
    "                P_store[i_epoch,i_long,:,:,:] = P_inv_t.copy()\n",
    "                Energy_store[i_epoch,i_long,:] = Energy_t.copy()\n",
    "                i_long += 1\n",
    "                print('Step', i_mc, 'Energy (temper = 1):', Energy_t[4])\n",
    "        \n",
    "        if (i_mc == steps_middle_0 ):\n",
    "            P_intermediate_shot[0,:,:,:] = P_inv_t.copy()\n",
    "            E_intermediate_shot[0,:] = Energy_t.copy()\n",
    "            \n",
    "        if (i_mc == steps_middle_1 ):\n",
    "            P_intermediate_shot[1,:,:,:] = P_inv_t.copy()\n",
    "            E_intermediate_shot[1,:] = Energy_t.copy()\n",
    "            \n",
    "            \n",
    "        energies_pasos[:, i_mc] = Energy_t[:]\n",
    "        count_mc += 1\n",
    "        for i_micro in range(Nx):\n",
    "            count_parallel,P_t, P_inv_t, Energy_t, ovlp_t0, ovlp_t1, L_t,suma_L_t = parallel_groups( count_parallel,fijado,n_groups, groups_anch_t,start_anchor, \n",
    "                                                                                                     end_anchor, A, P_t, P_inv_t, L_t,suma_L_t, Energy_t, ovlp_t0, \n",
    "                                                                                                     ovlp_t1, tempers, i_mc)\n",
    "    \n",
    "            \n",
    "    \n",
    "\n",
    "    print('Final energy:', Energy_t)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Elapsed (after compilation) = %s\" % (end - start))  \n",
    "\n",
    "Energy_calculada = np.zeros((N_t))\n",
    "for k_nt in range(N_t):\n",
    "    Edges_L= K*sum(sum(L_t[k_nt,:,:]))\n",
    "    Edges_NoL = Edges_sum - Edges_L\n",
    "    overlap_0, overlap_1 = overlap_total_prob(L_t[k_nt,:,:],A,P_inv_t[k_nt,:,:])\n",
    "    Energy_calculada[k_nt] = hamiltonian_prob(Edges_NoL, Edges_L, overlap_0,overlap_1,alpha, beta)\n",
    "    \n",
    "print('Final energy:', Energy_t, '// Checking:', Energy_calculada) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd25a9-e17c-4c9c-8a4f-1897e2b5b88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.arange(PasosMC)\n",
    "for k_nt in range(0,N_t):\n",
    "    energies_pasos_temper = energies_pasos[k_nt,:] \n",
    "    plt.plot(x,energies_pasos_temper,'.',label='%s temper' % tempers[k_nt])\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('Energy per node')\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in a dictionary\n",
    "d_store={}string = \"Drosophila_5_0.pickle\"\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "d_store[\"groups\"] = groups_store\n",
    "d_store[\"start_anchor\"] = start_anchor\n",
    "d_store[\"end_anchor\"] = end_anchor\n",
    "d_store[\"n_groups_anchor\"] = grupos_extra\n",
    "d_store[\"Anchors\"] = Anchors\n",
    "d_store[\"E_groundtruth\"] = Energy_ground_truth \n",
    "d_store[\"Pasos_corr_ini\"] = Pasos_corr\n",
    "d_store[\"Step_corr\"] = Long_corr\n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b48e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_store={}\n",
    "d_store[\"Datos_energy\"] = energies_pasos\n",
    "d_store[\"Permus\"] = P_t\n",
    "d_store[\"E_store\"] = Energy_store\n",
    "d_store[\"Permusstore\"] = P_store\n",
    "d_store[\"L_latent\"] = L_t\n",
    "d_store[\"temper\"] = tempers\n",
    "d_store[\"A\"] = A\n",
    "d_store[\"start_groups\"] = start_groups\n",
    "d_store[\"end_groups\"] = end_groups\n",
    "d_store[\"groups\"] = groups_store\n",
    "d_store[\"start_anchor\"] = start_anchor\n",
    "d_store[\"end_anchor\"] = end_anchor\n",
    "d_store[\"n_groups_anchor\"] = grupos_extra\n",
    "d_store[\"Anchors\"] = Anchors\n",
    "d_store[\"E_groundtruth\"] = Energy_ground_truth \n",
    "d_store[\"Pasos_corr_ini\"] = Pasos_corr\n",
    "d_store[\"Step_corr\"] = Long_corr\n",
    "\n",
    "file1 = open(string,\"wb\")\n",
    "pickle.dump( d_store, file1)\n",
    "prueba = pickle.load(open(string, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d69ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
